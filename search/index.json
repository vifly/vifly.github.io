[{"content":"在用了近三年的 Material 主题后，我终于决定更换博客主题了。尽管当初在我开始写博客时，Material 主题已经不维护了，但我暂时没找到更符合自己需求的主题，于是便一直用到了现在。当然，那时的我已经有将来会更换主题的预感了，而如今这一只脚终于落地，给博客换上了看上去更现代的 Stack 主题，也从 Hexo 迁移到了 Hugo，于是写下本文说明一下相关的经过（又能水一篇博文了）。\n为什么要换主题 先列举一下旧方案的不足吧。Material 主题并不差，设计风格符合我的胃口，而且提供了我所需要的功能，但用了这么久，由于各种原因令我想更换博客主题：\n Material 主题已经不再维护，这是最核心的一个问题，考虑到前端圈在兼容性方面的“良好”名声，我毫不怀疑哪天 NodeJS 或 Hexo 一个更新就会令我的博客没法构建 感觉当年的 Material Design 有点跟不上时代了（喜新厌旧），另外展开侧边栏时的动画给我的感觉有点慢，令我不禁怀疑在 PC 端模拟 Android 端 Material Design App 的必要性 友链界面的卡片有一点问题，当描述较长时会出现文字溢出的问题，原本打算咬咬牙修一下 CSS 的，但想到迟早要换博客主题，不如赶快换了主题再处理友链界面  另外，还是由于偏主观的对前端工具链的不信任，我不想再用 Hexo 了，切换到使用自己更熟悉的语言写的静态站点生成器至少能确保在出现问题时我可以尝试自己动手修一修，所以 Python 写的 Pelican 和 Go 写的 Hugo 对我来说都是不错的选择（PS：为什么还没人用 Rust 造一个强大的静态站点生成器）。\n迁移过程 先根据 Hugo 官方的 Quick Start 下载 Stack 主题并建了一个简单的站点，然后一步步把博客原有的配置迁移过去。\n其中比较费时间且烦琐的步骤包含把 Stack 主题提供的示例配置从 YAML 改为了 TOML 文件（非必要，个人偏好原因）；以及更改文章源码的结构：原本我是把所有的 Markdown 文件放在一个文件夹下，文章配图放到另外的文件夹，现在由于 Stack 主题的要求我给每篇博文新建了文件夹并把配图移动到对应博文所在的文件夹。\n由于不是新建博客而是迁移博客，所以我还处理了 URL 相关的问题，确保原来的 URL 不变。在迁移前，我的 Markdown 文件都是像 Python_GIL_and_concurrency.md 这样首字母与专有名词大写，下划线用于分割单词的格式，Hexo 生成的博文 URL 与文件名相同；迁移后，每篇博文都放到单独的文件夹，具体存放结构可在此查看，按照 Stack 主题给的示例所生成的博文 URL 则是 viflythink.com/\u0026lt;文章标题\u0026gt;/ 的格式，我经过谷歌后按照 Hugo 文档设定了新的 URL 生成规则：\n[permalinks] post = \u0026#34;/:filename/\u0026#34; page = \u0026#34;/:slug/\u0026#34; 这样就会用文件夹的名字而不是用文章标题来生成 URL，当然，这还不够，生成的 URL 虽然用的是文件夹的名字，但全都转为了小写字母，然后找到这篇文章让 Hugo 生成大小写敏感的 URL：\ndisablePathToLower = true 除了博文的 URL 外，还需要处理 RSS 订阅地址，原来的 RSS 地址是 viflythink.com/atom.xml ，可 Stack 默认产生 viflythink.com/index.xml 作为 RSS 地址，于是我又谷歌找到了 Hugo 论坛的讨论，据此修改了设置：\n[outputFormats.RSS] mediatype = \u0026#34;application/rss\u0026#34; baseName = \u0026#34;atom\u0026#34; 除了让 URL 保持不变外，我还设法把原本对 Material 主题修改的代码也迁移了过来。这里不得不提到 Hugo 的 Theme Components，通过它我可以在站点根目录下建立同样结构的目录以覆盖主题的部分内容，也就是说不用直接对主题的源代码动手了，接下来的修改都是靠这个特性完成的，具体可参考 Stack 的修改主题章节。\n与 Material 主题相同，Stack 没有提供 Isso 评论系统，新建 layouts/partials/comments/provider/isso.html 并按 Isso 文档的说明把内容复制粘贴进去就能添加对 Isso 的支持了（别忘了修改站点配置文件）。\n还有验证网站所有权与插入 Matomo 统计代码都是通过新建与修改 layouts/partials/head/custom.html 完成的。设置 CNAME 让 viflythink.com 指向 vifly.github.io 则是新建 /static/CNAME来完成（来源：Hugo 文档）。\n我还想把随机标语也迁移到 Stack 上，这就需要覆盖主题原本的文件了。把 themes/hugo-theme-stack/layouts/partials/sidebar/left.html 复制为 layouts/partials/sidebar/left.html，然后对 \u0026lt;h2 class=\u0026quot;site-description\u0026quot;\u0026gt;{{ .Site.Params.sidebar.subtitle }}\u0026lt;/h2\u0026gt; 进行修改，具体的修改可看我的代码，如何在 Gist 存放标语内容则请看我的旧博文《使用 GitHub Pages 和 Hexo 搭建个人博客(进阶篇)》中的“Material 主题实现随机显示标语（slogan）”一节。PS：翻阅旧博文后发现自己的前端技术也有所进步了，当年只会用一下 jQuery，而现在直接用 Vanilla JS 的 fetch 就完成了相同的任务。为了让修改后的侧边栏看上去更好，我还微调了一下样式，具体可看 assets/scss/partials 下的内容。\n最后，我还把博客的构建从本地搬到了 GitHub Actions 上，当我把修改的 Markdown 文件推送到 GitHub 后博客就会自动更新，再也不用在本地构建好后再推送到 GitHub Page 所在的仓库了。\n总的来说，迁移过程可说是十分平滑，没有踩到任何大坑就把博客迁移到 Stack 主题了，甚至没花多少时间就把对 Material 主题的修改也搬了过来。\n新变化 既然把博客主题换了，那肯定要对比一下迁移前后的外观。\n 使用 Material 主题的博客主页 \n 使用 Stack 主题的博客主页 \nStack 主题是典型的三栏式布局，右侧栏包括了常用的跳转链接与搜索功能，而 Material 则是单栏，侧边栏需要点击按钮才会出现。至于在主页上的博文呈现，两者都是卡片风格，同样是由上到下的图片 -\u0026gt; 标题 -\u0026gt; 文章摘要这样组成的布局。可以看出两者给人的感受有所区别，迁移到 Stack 主题后我博客的风格更柔和多彩了，这得益于圆角的使用与主题配色的区别，当然，也与我在迁移后给文章配上精心挑选的图片有关，之前的文章图片都是由 Material 自动生成的，虽然也挺好看，体现了 Material Design 的简洁风格，但看久了后总会觉得千篇一律。\n除了外观上的变化，细心的读者可能会发现，在迁移后，我的博客左侧栏多了 Service 这一个链接，这是我新增的一个页面，用于列举出目前我提供的服务，当提供的服务有改动时，该页面也会有所说明。\n另外，有一个读者无法察觉但我能明显感知到的变化：迁移后的博客构建速度变快了。这大概是 Hugo 的优化比 Hexo 好导致的，不过并不能完全怪罪 Hexo，因为这也与我之前用的 Material 主题许久不更新，没有用上 Hexo 的用于加快构建速度的新特性有关。总之目前的构建速度终于让我感到舒服了，能够快速看到改动效果这一点在修改主题样式时十分有用。\n总结 我有时会开玩笑说：“写博客哪有写博客主题有意思”，包括这次迁移在内，看着刚开始时一个标准的模板被改造成了自己想要的样子的确很有意思，但我认为开设博客的目的更应该是写一些自己觉得有价值的内容，博客的外观与设计的确很重要，体现了博主的品位与喜好，但世界上并不缺少能展示自己品位的方法，写博客却是少有的通过文字阐述观点、分享知识与经历的行为，所以我会尽量不让与网站相关的博文占到总博文数的一半，而是尽量让博客涉及更多领域的内容，这也是我为本博客所设立的一个目标。\n最后，希望本次愉快的博客迁移能激励我提高一些更新博客的频率（咕咕咕）。最近来说，我也有了一些新想法，考虑到不是所有的新想法都有必要写一篇博文来说明，未来我可能会在其它平台（Twitter、Telegram 频道等）或另一个自建站点记录与说明这些东西，也可能会考虑建立公开 Wiki 知识库这样的站点来分享自己的知识，总之这些都是目前只存在于脑海中的想法，这些任务就交给未来的自己了。本篇水文到此结束，谢谢有耐心读到最后的读者。\n","date":"2021-11-21T00:00:00Z","image":"https://viflythink.com/Migrate_from_Material_to_Stack/show_hu7d264867c8d78abf58e9b67e98a77df9_254555_120x120_fill_q75_box_smart1.jpg","permalink":"https://viflythink.com/Migrate_from_Material_to_Stack/","title":"从 Material 主题迁移到 Stack 主题"},{"content":"这是我第二次参加 Hackergame 了，今年依然玩的很开心，感受到了来自不同领域的考验，更开心的是与上一年的 800 分相比，今年拿到了 1150 分，有所进步😂。虽然我做出来的题并不多，而且有些简单的题目没解决，但还是写一篇博文提供题解吧。希望本篇博文能够帮到想参加 Hackergame 的各位小伙伴。\n签到 与上一年的签到题相比，今年连脑筋急转弯都不需要了，每次点 Next 时间都会 +1s（唐突玩梗），我们只要把时间翻到本届大赛的举办日期即可，也就是说需要计算出 1970 年 1 月 1 日与 2021 年 CTF 大赛的时间差（用秒表示）。这里随便选取一个符合 2021 年 CTF 大赛时间范围的时间，然后使用 Python 计算：\nimport datetime today = datetime.datetime(2021, 10, 25) begin = datetime.datetime(1970, 1, 1) delta = today - begin print(int(delta.total_seconds())) 由于可选的范围较大，所以代码不考虑时区且日期只精确到日，最后得到 1635120000 这个数字，那么访问 http://202.38.93.111:10000/?page=1635120000 就可以得到 flag 了。\n 成功获取签到题的 flag \n进制十六——参上 X 同学不会退出 Vim 着实让我笑了（知名勒索软件），只不过这题虽说标题含有十六进制，但主要考验的是参赛者对 ASCII 码的了解。看到图片中的数字时很容易就会猜测这是不是 ASCII 码，通过 man ascii 查十六进制表进行对比，发现前面的几个数字与图片右侧开头的字母完全能对上，那么接下来就简单了。先找到 flag 的开头，查表得“flag{”对应的十六进制 ASCII 码是 66 6C 61 67 7B，而末尾的“}”对应的是 7D，把图中属于这部分的数字手打出来，然后用 Python 进行转换即可，这里我直接抄 stackoverflow 上的回答：\ns = \u0026#34;66 6C 61 67 7B 59 30 55 5F 53 48 30 55 31 44 5F 6B 6E 30 77 5F 48 30 57 5F 74 30 5F 43 30 6E 76 33 72 74 5F 48 45 58 5F 74 6F 5F 54 65 78 54 7D\u0026#34; l = list(map(lambda x: int(x, 16), s.split())) print(\u0026#39;\u0026#39;.join(map(chr, l))) 猫咪问答 Pro Max 与上一年的猫咪问答++一样，都是考验参赛者的信息搜索能力，我依然是采用了部分问题搜寻答案，另一些问题用脚本暴力破解的方案（脚本都没怎么改）。\n第一小题有点意思，题目提到信息安全俱乐部的域名（sec.ustc.edu.cn）已经无法访问，如何找到现在已经无法访问的网页上的资源呢？答案当然是网页快照，这里我选择了 Wayback Machine，其记录的社团章程页面正文第一句话就是“本章程在 2015 年 5 月 4 日，经会员代表大会审议通过。”，所以答案是 20150504。\nPS：对于中国大陆的网民来说，想看的文章 404 是一个家常便饭的事情，感谢 Wayback Machine 等提供网页快照的组织，他们让互联网的记忆不再转瞬即逝，避免了互联网内容的永久消失，运营这些服务所耗费的资源是巨大的，如果你有能力的话，可以考虑向 Wayback Machine 捐款以支持他们继续运营下去。\n第三小题可以通过搜索“中国科学技术大学 Linux 用户协会 西区活动室”这些关键词找到对应的新闻稿，其中就有现场照片，翻看图片得到 Development Team of Library 这个答案。\n第五小题又是一个愚人节玩笑，谷歌找到对应的 RFC，在 Table of Contents 中看到存在 Reporting Offenses 这一章节，跳到该章节看到“Send all your reports of possible violations and all tips about wrongdoing to /dev/null.”这一句话提供了答案，所以本题的答案是 /dev/null。\n剩下的题目就是靠脚本解决了。\n卖瓜 不知道是不是每一届 Hackergame 的 Web 类都会有一道题目涉及数值运算。6 斤与 9 斤的瓜在放整数个的情况下是不可能凑够 20 斤的，我一开始以为这题需要想办法弄出浮点数，但经过了多次尝试后发现这题需要利用数值溢出来解决。随意尝试输入一个很大的数字，可以发现当输入的数值超过一定范围时正数会溢出变为负数。试了好一会后发现添加 5944674407370955162 个 9 斤的瓜后会导致记录变为 -1838162554790060032 斤，我们的目标是 20 斤，-1838162554790060032 加 20 正好是 9 的倍数，(-1838162554790060032 + 20) / 9 得到 -204240283865562228 这个数字，这个数并不会导致溢出，也就是说先加 5944674407370955162 个 9 斤的瓜，然后再加 204240283865562228 个 9 斤的瓜就可以凑够 20 斤了。前面进行尝试时顺便写了个脚本，于是最后用它提交并获得了 flag。\nAmnesia 轻度失忆 这是我第一次成功解决了一道 binary 类的题目！尽管只是完成了第一小题，但依然觉得非常开心。在轻度失忆的情况下，.data 和 .rodata 段会被清除，要知道这两个段是什么东西呢，就需要对 ELF 格式有所了解。一般来说，Linux 下我们编译后得到的产物都是 ELF 格式的，例如 file /bin/bash 会告诉我们 bash 是一个 x86 体系架构的 ELF 格式的可执行文件，ELF 要求把编译产物的不同部分放到不同的分段（section，不是 segment），具体有哪些分段，它们分别存放什么，OSDev Wiki 提供了一个表格进行说明。从表格可以得知 .data 段用来存放已初始化的全局变量等数据，而 .rodata 段用来存放不变的数据。既然这两个段会被清空，那么我们就不能把含有 “Hello, world!” 的字符串放到这些地方，在这里不得不说到 C 语言的一个麻烦点：C 语言中并不存在真正的字符串，所谓的字符串本质上是字符指针或字符数组。使用字符指针的话，在初始化时该指针会指向包含“Hello, world!”的只读数据（在 .rodata 段），所以字符指针不能用在这里，只能采用字符数组进行储存。同时也不能把该字符串放到函数外作为全局变量。另外，为了防止 printf(\u0026quot;%s\u0026quot;, s); 中的 %s 被清除，这里使用 putchar 函数把字符一个个输出。\n#include \u0026lt;stdio.h\u0026gt; int main() { char s[] = \u0026#34;Hello, world!\u0026#34;; for(int i = 0; i \u0026lt; 13; i++) { putchar(s[i]); } return 0; } 在编译完成后可以通过 objdump -s -j .rodata hello_world 与 objdump -s -j .data hello_world 检查 .data 和 .rodata 段是否还存在数据（自行替换文件名）。\n图之上的信息 GraphQL 是一种新颖的接口设计方案，也是我目前还不了解的一个玩意，只不过我根据题目位置和分值推测这道题目的难度应该较低，抱着试一试的心态用谷歌搜寻了 GraphQL 的常见安全问题，然后发现这篇博文，还以为需要多动手试验几次，可没想到用文章里推荐的 GraphQLmap 就直接扒出了整个接口可用的字段（需要先靠浏览器 F12 找到接口地址和其它信息）。\n 获取所有字段 \n知道字段后就好办了，只要没有另外的身份验证，接下来直接查询 admin 的邮箱即可。根据 GraphQL 官方文档写出查询语句，此处需要填入参数，由于 guest 账号的 id 为 2，所以猜测 admin 的 id 为 1。在 GraphQLmap 内执行 {user(id: 1) {privateEmail}}，好了，黑客扒库成功。\n 成功获取图之上的信息的 flag \nPS：我后来才发现服务端没禁用 introspection，例如我查询 users 时服务端会提示是不是想查询 user，所以其实不用 GraphQLmap，执行以下查询就可以取得所有字段了。\n{__schema{queryType{name}mutationType{name}subscriptionType{name}types{...FullType}directives{name description locations args{...InputValue}}}}fragment FullType on __Type{kind name description fields(includeDeprecated:true){name description args{...InputValue}type{...TypeRef}isDeprecated deprecationReason}inputFields{...InputValue}interfaces{...TypeRef}enumValues(includeDeprecated:true){name description isDeprecated deprecationReason}possibleTypes{...TypeRef}}fragment InputValue on __InputValue{name description type{...TypeRef}defaultValue}fragment TypeRef on __Type{kind name ofType{kind name ofType{kind name ofType{kind name ofType{kind name ofType{kind name ofType{kind name ofType{kind name}}}}}}}}  当 introspection 被启用时的查询结果 \n加密的 U 盘 与上一年 Hackergame 的室友的加密硬盘一样都涉及到了 LUKS，上一年的题目由于没想到冷启动攻击这种高级玩意没做出来，今年的题目相比起来就简单多了，对 LUKS 的原理有一定了解的前提下可以很快找到思路。LUKS 有一个很有趣的设计，当我们解密使用 LUKS 加密的分区时，首先会使用我们输入的密码解密位于加密分区头部的主密钥（master key），此时使用的算法在设计上故意令运算速度非常慢（LUKS1 默认的是 PBKDF2），以此给尝试暴力破解的攻击者增加时间成本，然后才会使用这个主密钥解密分区内容，而此时算法的性能就非常好（默认采用 aes-xts-plain64，使用 cryptsetup luksFormat 创建加密分区时可以通过 \u0026ndash;cipher 参数指定其它算法，通过 cryptsetup benchmark 查看各种算法的性能指标），不会让用户觉得访问速度慢。\n知道了上述这一点后，我们可以想一想 day1 与 day2 这两个镜像会有什么区别，虽然 day2 的密码已经被改了，可两者之间是否有什么东西没有改变呢？答案就是主密钥没变。利用这点，我们可以从能够解密的 day1.img 中提取出主密钥，然后用主密钥解密 day2。\n先根据该回答把两个镜像文件附到（attach）Loop 设备，并解密挂载 day1.img：\nsudo losetup -P /dev/loop1 ./day1.img sudo losetup -P /dev/loop2 ./day2.img sudo cryptsetup open /dev/loop1p1 day1 mkdir /tmp/day1 sudo mount /dev/mapper/day1 /tmp/day1 接下来原以为按 RedHat 的文章操作就行了，没想到 LUKS2 不支持通过 dmsetup 获得 masterkey，那么只能先用 cryptsetup 导出主密钥了：\nsudo cryptsetup luksDump /dev/loop1p1 --dump-master-key 这会警告你输出的信息很敏感，需要另外输入大写的 YES 进行确认才能继续。获得输出后复制 MK dump 里的一长串十六进制数，并用 xxd 进行转换，最后解密 day2.img：\necho \u0026quot;be 97 db 91 5c 30 47 ce 1c 59 c5 c0 8c 75 3c 40 72 35 85 9d fe 49 c0 52 c4 f5 26 60 af 3e d4 2c ec a3 60 53 aa 96 70 4d f3 f2 ff 56 8f 49 a1 82 60 18 7c 58 d7 6a ec e8 00 c1 90 c1 88 43 f8 9a\u0026quot; | xxd -r -p \u0026gt; masterkey sudo cryptsetup open /dev/loop2p1 day2 --master-key-file ./masterkey mkdir /tmp/day2 sudo mount /dev/mapper/day2 /tmp/day2 cat /tmp/day2/flag.txt 这是一种比较难以利用的破解 LUKS 的方式，需要取得已无效的密码与该密码有效时的 LUKS 分区。当然，这也提醒我们旧的加密数据最好不要随便公开，没准攻击者就靠这点破解了新的加密数据呢。\n赛博厨房 Level 0 第零天的菜谱是“0,1”，而写好指令后第一天变成了“1,1”，那只能更改指令重新学习后执行。指令如下：\n向右 2 步 拿起 2 个物品 向下 1 步 向左 2 步 放下 1 个物品 放下 1 个物品  Level 0 flag \nLevel 1 看到菜谱包含了这么多的 0，先复制并用 Python 统计总共有多少个 0，得到 73 这个数字。\n接下来又是拿起物品并放下的流程了，别忘了一次只能放下一个物品，所以我们需要 73 次放下，这就需要构造一个循环语句了，如果把循环展开为 73 行“放下 1 个物品”，题目会由于行数过大而不予通过，具体指令如下（使用 goto 实现循环可真难受）：\n向右 1 步 拿起 73 个物品 向下 1 步 向左 1 步 放下 1 个物品 如果手上的物品大于等于 0 向上跳转 1 行  Level 1 flag \n一些没做出来的题目 不知道为什么，今年与上一年类似，一些题目看似很简单，可我就是没做出来，赛后看到题解时差点吐血，原来我就只差一点点就解决了。\n“去吧！追寻自由的电波”，这题我已经发现 ffmpeg -i radio.mp3 -af \u0026quot;atempo=0.5,asetrate=22050\u0026quot; res.mp3 可以输出能让人听清楚读音的音频，而且也找到了无线电领域所使用的字母表，可惜就差 November 这一个字母没听出来。\n“透明的文件”，当我写 rgrcat 这个项目时（咕咕咕）已经了解到了 ANSI 转义序列，知道它可以让程序的输出附上颜色，所以我在每个“[”前加上了“\\033”，唯一没想到的是还需要把所有空格替换为其它字符，不然会看不到输出。\n“Easy RSA”，看到题目说“你还获得了构造 p 和 q 的方式”，我还以为今年终于能解决一道 math 类的题目，可惜自己的数理基础太差，连怎么计算 p 都没想到，只能明年继续努力了。\n“FLAG 助力大红包”，还以为需要在应用层以下的协议栈当中寻找伪造 IP 的办法，没想到反代服务器存在 X-Forwarded-For 欺骗漏洞，可以很轻松地伪造 IP，这也提醒我以后在涉及 IP 识别的代码中不要信任 X-Forwarded-For 头标。\n总结 今年的中科大信息安全大赛依然很好玩，就算没解决题目，很多题目的描述看了以后都让我发出了笑声。虽然做出来的题目不多，但面对每道题目都绞尽脑汁寻找解题方法时的感觉非常美妙。今年也是我第一次做出来一小道 binary 类题目，当然，我在这方面的基础还是不够，只能多学习点东西，在明年的 Hackergame 尝试再进一步。\n","date":"2021-10-31T00:00:00Z","image":"https://viflythink.com/Hackergame_2021_writeups/show_hued1753f52dabbdb4ad30a094c50ac508_1372538_120x120_fill_q75_box_smart1.jpg","permalink":"https://viflythink.com/Hackergame_2021_writeups/","title":"2021 中科大信息安全大赛题解"},{"content":"2021.11.12.更新：增加了关于 GPG 签名的说明。\n大家好，又是本鸽子久违的博客更新。之前的《GitHub Actions 打造 AUR 打包下载一条龙服务》已经折腾出了完全白嫖的编译机，可好景不长，当我的机器数量变多后，我发现在每台机器上运行脚本下载软件包的确有点麻烦，与其自己写一个脚本下载软件包，还不如直接自建一个软件源呢。经过一番研究后，我盯上了 OneDrive 与 Vercel 这两个可以免费使用的服务，通过它们实现了自建一个完全免费而且在国内外都可高速访问的软件源。\n本文是对《GitHub Actions 打造 AUR 打包下载一条龙服务》的扩展，如果你还没有读过该博文，请先读完它再回来阅读本文。通过前文与本文，你可以在没有服务器，不花一分钱的情况下搭建一个基于 OneDrive 的高速自建软件仓库，体验到白嫖与折腾 Linux 的双重快乐。\n为了得到一个公开的软件仓库，只是把软件包构建出来并放到 GitHub Release 是不够的，没有软件包数据库，软件包管理器可不知道如何获取这些软件包，更不用提校验与安装等等。生成软件包数据库只需要一行 repo-add ./reponame.db.tar.gz *.tar.zst，然后把它们都放到 GitHub Release 这样的免费存储后端就可以解决分发问题了，实际上有一个 arch-build 的 fork 就是这样做的。当然，我对其还是不够满意，通过 fastgit 等 GitHub 反代服务的确可以加速 GitHub Release 的下载速度，但还是不够稳定；还有一个更重要的原因，我不仅想要自建 Arch 软件源，也想要自建 Debian 软件源，而 GitHub Release 的路径不够灵活，无法构造像 yourrepo.com/debian/pool/main/n/nginx/ 这样的 URL，没法满足自建 Debian 软件源的需求。所以嘛，只能自己再造一个轮子了。\n在看下文之前，不妨先打开我的自建仓库页面查看最终效果，如果想使用我的自建软件源，需要先执行以下指令导入 GPG 公钥：\nwget -O /tmp/vifly-repo.key 'https://share.viflythink.com/arch-repo.key' \u0026amp;\u0026amp; sudo pacman-key --add /tmp/vifly-repo.key sudo pacman-key --lsign-key viflythink@gmail.com 然后在 /etc/pacman.conf 末尾添加下面几行后执行 pacman -Syu：\n[vifly] Server = https://archrepo.viflythink.com 尽管本文最终提供的成品目前只用在 Arch 自建源上，但对脚本稍加修改后也可以用来自建其它 Linux 发行版的软件仓库。\n上传到 OneDrive 之前配置的 GitHub Actions 已经可以把软件包上传到 Release 上，现在只需要对原来的配置文件稍加改造就可以让 GitHub Actions 把软件包也上传到 OneDrive，为了尽量不重复造轮子，在这里我选择了 Rclone 进行上传，它提供了非常完善的文件传输功能，例如上传或下载时遇到文件内容相同的情况会自动跳过。\n在 Azure 创建应用 根据 Rclone 的官方文档操作即可，以下给出图文操作步骤。尽管 Rclone 官方认为这是可选的，但在 Vercel 部署直链下载应用时也需要在 Azure 创建应用获取 Token，所以便把相关步骤放这里了，另外基于权限最小化的原则，这里我们创建的是一个拥有读写权限的应用，而在 Vercel 部署时则是创建一个具有只读权限的应用，两个应用用在不同的地方，这样可有效提升安全性。\n打开 Azure 的应用管理页面，点击 New registration。\n Azure 应用列表 \n在打开的界面中输入应用的名字（这里我用了 rclone 这个名字），Supported account types 这一项选择 Accounts in any orGitHub Actionsnizational directory，在 Redirect URI (optional) 这一项选择 Web 并在右边的输入框里输入 http://localhost:53682/ 这一网址。完成后点击 Register。\n Azure 注册应用 \n此时应用已经注册完成，记录下 Application (client) ID 的值，这就是下文会用到的 client id。\n Azure 获取 client id \n点击左侧菜单的 Certificates \u0026amp; secrets，然后点击 New client secret，在 Description 一栏随便填点什么，把 Expires（过期时间）设为最长的 24 months（两年后记得更新 client secret），点击 Add。最后记录下新增的 client secret 的值（在图中标注的 Value）。\n Azure 获取 client secret \n到此为止就完成了。有些同学可能会感到奇怪：Rclone 文档中不是还有第 4 与第 5 步设置权限吗？根据我的实测，这两步并没有必要执行，所以这里不会附上这两步操作的示意图。\n获取 Token 在本地安装 Rclone（pacman -S rclone），运行 rclone config 进入交互式配置流程，接着一步步地按照提示操作，当程序询问 Microsoft App Client Id 和 Microsoft App Client Secret 时，填入上一小节中记录的对应值。\n完成配置后 Rclone 会把配置数据存放在 ~/.config/rclone/rclone.conf，使用 cat ~/.config/rclone/rclone.conf 查看。如下所示，下文需要复制对应的值时只需要把等号右边的东西按原样复制粘贴就行了。\n[xxx] type = onedrive client_id = xxx client_secret = xxx region = global drive_type = personal token = {\u0026#34;access_token\u0026#34;:\u0026#34;xxx\u0026#34;,\u0026#34;token_type\u0026#34;:\u0026#34;Bearer\u0026#34;,\u0026#34;refresh_token\u0026#34;:\u0026#34;xxx\u0026#34;,\u0026#34;expiry\u0026#34;:\u0026#34;xxx\u0026#34;} drive_id = xxx PS：一点安全提醒，在我们的用例中，client id 与 client secret 都可以公开，但 token 是绝对不能公开的。\n配置 GitHub Actions 首先 fork arch-build 仓库，如果你在之前已经使用了它，记得同步到最新版本。与前文所给的例子相比，现在的 workflow 文件（.github/workflows/build.yml）多了 uploadToOneDrive 这一个 job，而用到的 action 需要填入近十个参数，参数量的确很多，接下来让我介绍一下该如何填写这些参数。\n${{ secrets.xxx }} 这样的变量都是需要在 GitHub 的项目配置中的 Secrets 一栏设置的私密变量，打开项目的 Settings，找到下图所示的界面，然后点击 New repository secret，并填入 RCLONE_ONEDRIVE_CLIENT_ID、RCLONE_ONEDRIVE_CLIENT_SECRET、RCLONE_ONEDRIVE_TOKEN、RCLONE_ONEDRIVE_DRIVE_ID 这四个变量的值（从上一小节的 rclone.conf 中获得）。具体的操作也可参考 GitHub 官方文档。\n GitHub Actions 添加私密变量 \n接着回来修改 workflow 文件，RCLONE_ONEDRIVE_REGION 与 RCLONE_ONEDRIVE_DRIVE_TYPE 也是按 rclone.conf 的值填写；而 dest_path 是 OneDrive 上传的目的地路径（如果该路径不存在，Rclone 会自动创建），以 Linux 文件路径的形式填写即可，不建议使用根路径，因为接下来将会把这个路径下的所有东西公开，各位肯定不希望别人打开你的软件仓库页面时还看到其它乱七八糟的文件；repo_name 是你的自建软件仓库的名字，它用于 repo-add 的参数。\n为了安全，建议为自己的软件源添加 GPG 签名，不签名的话，pacman.conf 中的仓库配置需要加上 SigLevel = Never 禁用签名校验才能使用。如果你想为自己的软件源添加 GPG 签名的话，建议先生成一个单独的 GPG 密钥对（不要设置密码），而不是使用原有的密钥对，并导出私钥：\ngpg --gen-key gpg --armor --export-secret-keys your_keyid \u0026gt; private.key 回到 GitHub 的项目配置新增 Secrets，Name 为 gpg_private_key，Value 则是导出的私钥内容。最后在 workflow 文件的 uploadToOneDrive job 的参数加上 gpg-privatekey: ${{ secrets.gpg_private_key }}（即 dest_path、repo_name 等配置所在的位置）。现在得到的软件源将具有 GPG 签名，需要按以下步骤导入公钥才能使用：\ngpg --armor --export your_keyid \u0026gt; public.key sudo pacman-key --add public.key sudo pacman-key --lsign-key your_keyid 为了节省存储空间，这个 job 只会在 OneDrive 存储最新版本的软件包，不像 Arch 官方软件仓库那样还提供了归档。如果你对使用 Rclone 同步到 OneDrive 或构建软件包数据库的细节感兴趣，那么可以查看 entrypoint.sh 脚本了解细节，不到三十行便完成了这些工作（其实是因为我把复杂的逻辑用 Python 实现了）。\n在 Vercel 部署直链下载应用 上面我们已经把软件包成功放到了 OneDrive 中，OneDrive 本身也有分享功能，可是它的分享链接地址没有任何的规律，Pacman 可不知道一个软件包对应的下载地址与 OneDrive 分享地址的联系，它只认 yourrepo.com/package 这样的下载地址（Apt 等包管理器认的 URL 更复杂，但依然有明显的规律），所以我们需要一个应用来实现链接的转换，这就是直链下载应用要干的事情。\nGitHub 上已经有不少 onedrive index 项目实现 OneDrive 的直链下载，我嫌它们提供的功能太多了（没忍住自造轮子的冲动），所以也用 Python 造了一个非常简陋的应用 urepo，支持在 Vercel 上部署，也支持直接在 VPS 上部署，它和 Rclone 一样采用了微软官方提供的 API 实现提取文件下载链接的功能。下文将使用 urepo 实现直链下载，如果你之前已经部署了其它的 onedrive index 应用，那参照下文继续用原来的应用也是可以的。\n获取访问令牌 既然 urepo 和 Rclone 一样采用了微软官方提供的 API，那么它同样也要像使用 Rclone 那样获取访问令牌。回到上面的“在 Azure 创建应用”这一小节，按同样的步骤再创建一个应用，只是这次的 Redirect URI (optional) 应输入 http://localhost/ ，完成后得到 client id 与 client secret。\n与上面依靠 Rclone 获取 Token 不同的是，这次则是使用一个脚本获取 Token，它不会像 Rclone 那样申请写入权限。下载我写好的获取 Token 脚本与配置示例，并确保已经安装了 Python 的 Requests 库（pacman -S python-requests），然后把配置示例（config.py.example）重命名为 config.py，并填入 CLITENT_ID 与 CLITENT_SECRET。\n运行脚本：\ncd downloadpath python3 get_deploy_config.py 根据提示操作，最后得到 code 与 refresh_token。此时我们已经获得 client id、client secret、code、refresh_token 这四项配置。至于下文中需要用到的 path，那就是在“配置 GitHub Actions”这一小节中的 dest_path。\n部署到 Vercel Vercel 是一个免费的应用部署平台，主要用来测试和部署 Serverless 应用，通过它，我们可以零成本地部署直链下载应用。Vercel 提供了两种部署方式，从下面两种方式任选其一执行即可。\n打开链接部署（推荐） 注册或登录你的 Vercel 账号，然后打开我创建的部署链接，会出现如下界面，在 GitHub、GitLab、Bitbucket 这三个 Git 平台中选择一个进行连接，Vercel 会把 urepo 仓库复制到连接的平台上。\n Vercel 导入仓库 \n接下来的 Create a Team 只要点击 Skip 跳过就行，然后就是环境变量的设置，urepo 会首先尝试从环境变量中读取这些私密信息，无法找到对应的信息时才会去读取项目根目录下的 auth.json 获取配置，与把访问令牌写在配置文件相比，利用环境变量配置可以避免自己不小心把私密信息公开，根据上文填写这五个环境变量后就完成部署了。\n从本地上传部署 本方法需要安装 NodeJS 相关的工具链，我不太想和这些工具打交道，但 Vercel 本来是一个部署前端应用的平台，所以官方的客户端使用 JS 编写是很正常的事情，如果不想安装这些软件，那可以使用上面的部署方法。\n首先安装 Yarn 或其它 NodeJS 包管理器：pacman -S yarn，由于 JS 应用总是喜欢在用户的家目录乱丢东西，所以为了让 Yarn 遵循XDG 目录规范，我们可以执行 yarn config set prefix ~/.local。然后执行下面的指令全局安装 vercel 应用，这会把它安装到你的家目录（~/.local/bin，记得让你的 $PATH 包含这个路径）：\nyarn global add vercel 安装完成后执行下面的指令进行登录，在打开的浏览器窗口注册或登录你的 Vercel 账号并进行验证：\nvercel login 下载 urepo 源码：\ngit clone git@github.com:vifly/urepo.git 把 urepo 根目录下的 auth.json.example 重命名为 auth.json，然后把对应的配置填入里面。或者，也可以在上传部署后到 Vercel 的项目面板中设置 code、path、client_secret、client_id、refresh_token 这五个环境变量。\n Vercel 设置环境变量 \n最后就是上传部署：\ncd urepo vercel . 使用自己的域名（可选） 尽管 Vercel 会为部署的应用分配一个二级域名（xxx.vercel.app），但自建源使用自己的域名无疑是一个更好的选择。根据官方文档，首先需要打开项目的域名管理界面，添加自己想使用的域名。\n Vercel 添加域名 \n假设各位和我一样使用了自己的子域名，那么在自己的 DNS 解析服务提供商管理面板添加一条 CNAME 解析记录即可，我使用的是 cloudflare，还需要把代理状态设为“仅限 DNS”以确保不会使用 cloudflare 的反代。\n 在 cloudflare 设置指向 Vercel 的 CNAME \n有待改进的地方 尽管这一流程已经能工作了，但有些地方还是可以再改进一下的。首先，目前并没有数字签名，添加这一自建软件源时需要禁用对此的签名校验，在乎安全性的同学可能会对此表示不爽，所以日后有必要加上对软件包签名的支持。其次，urepo 应该无需修改就可以用于分发其它发行版的软件包与数据库（它的本质就是一个简陋的 onedrive index），但前面的 GitHub Actions 只支持 Arch，我未来肯定会加上对 Debian/Ubuntu 的支持，具体什么时候搞定这个，就要看我什么时候有需求了，对其它发行版的支持也是同样的😂。目前已支持 GPG 签名，也新增了 debian-build 用于构建 deb 软件包。\n另外，我编写的 urepo 与 GitHub Actions 脚本的报错信息并不够用户友好，由于大量采用了 Python 进行编写，假如出现错误的话对于没学过 Python 的同学来说可能难以根据输出的错误信息解决问题。这个问题也是留待日后解决。\n","date":"2021-09-04T00:00:00Z","image":"https://viflythink.com/Use_Vercel_and_OneDrive_to_setup_your_repo/show_hu3a92ba18b985a44b13d2086fb5d2cd73_887024_120x120_fill_q75_box_smart1.jpg","permalink":"https://viflythink.com/Use_Vercel_and_OneDrive_to_setup_your_repo/","title":"使用 Vercel 与 OneDrive 自建软件源"},{"content":"各位读者好，又是本鸽子久违的更新。最近在应聘后端开发岗位的过程中为了应对面试官各种奇怪的问题，特意整理了自己为 Python 并发编程所做的笔记，一看内容已经足够填满一篇博文了，那就作为新的一篇博文发布吧。\n由于并发（concurrency）与并行（parallelism）这两个词的意义总是纠缠不清，以至于有时会看到“Python 不支持并发”这样让我哭笑不得的说法，所以先明确一下在本文中这两个词的定义：根据还在疑惑并发和并行？的说明，我们把并行定义为同时有多个单位工作，这指的是运行时的状态，而并发则是一种程序结构设计，能够实现一段时间内执行逻辑上存在区别的多个操作。在应用程序层面，并发是并行的必要条件。\nPython 的 GIL 说起 Python 的并发，那么总是绕不开 GIL（全局解释器锁）这个东西，这就是导致我们采用的很多种并发手段无法实现并行的罪魁祸首，要注意的是并不是说所有并发手段都无法实现并行，例如多进程就可以。为了破解 Python 的并行难题，下面就让我们先解析一下这个让无数 Python 开发者怨声载道的 GIL。\nGIL 是什么 全局解释器锁（Global Interpreter Lock），顾名思义是一种锁，与我们平常在多线程环境下用到的锁不同，GIL 确保的是在同一时刻，在一个 Python 解释器中只有一个线程能够处于执行状态。回想一下我们写的 Python 代码是如何被执行的：在不考虑优化的情况下，Python 解释器一行一行地读取我们写的代码，然后把代码翻译为机器指令（准确来说是 bytecode）执行。GIL 就是对这个解释器上了一把锁，让它在任何时刻都只能执行一条指令。对于 GIL 的实现细节，可以在阅读完本文后参阅 GIL 的实现细节一文加深理解。\n需要注意的是，GIL 仅存在于 Python 官方的 CPython 实现和 PyPy 中，使用其它语言实现的 Python 解释器（如 Jython）并不存在这个限制，所以本文涉及 GIL 时所指的 Python 都是 CPython 实现。\n为什么需要 GIL 对于其它的主流语言（C/C++ 和 Java 等），它们并不会阻止在同一时刻多个线程的存在，为什么 Python 这么特殊，非要给解释器上一个锁，令我们写的多线程代码没法并行呢。\n不少人会回答这是为了解决 Python 的内存管理问题而引入 GIL。且慢，GIL 和内存管理有什么关系？准确来说 GIL 和内存管理中的垃圾回收（Garbage Collection，简称 gc）有关，假如你只学过 C 语言，那你可能在刚开始写 Python 时感到有点疑惑：为什么大家的代码在创建新对象后都不手动销毁，不会内存泄漏吗。然后你知道了 Python 有 gc，可以自动帮你回收不用的内存，像 Java、Go 等语言也有 gc，所以大家都不担心自己忘记销毁对象。可为什么其它具有 gc 的语言不存在 GIL 呢？这个问题可以从 Python 的起源获得一部分解答，Python 本身可以说是一个为了好玩而产生的项目，所以采用简单的方式实现 gc 是一个很合理的选择，这个简单的方式就是引用计数（学过 C++ 的同学是否觉得这个名词很熟悉）。经热心群友提醒，Python 的 gc 实现不只是简单的引用计数，还用到了分代 gc 作为优化手段，该 gc 实现并不是线程安全的。Python 中的所有东西都是对象，每个对象都有一个引用计数值，当一个对象的引用计数归零时（代表已经没有任何地方用到这个对象了），Python 就会销毁对象并回收对应的内存，以此实现自动管理内存。你可以通过以下方式查看对象的引用计数：\nimport sys a = [] b = a sys.getrefcount(a) 上文说到了引用计数对于 gc 的作用，接下来有个重要的问题：我们该如何确保在多线程环境下对象的引用计数是正确的呢？对并发有点了解的人肯定会回答，这就是一个竞态冲突问题，每次读写线程间共享的对象的引用计数前上锁就行了。的确，这样可以解决上述问题，但是，这可能导致死锁，此外频繁获取与释放锁会带来严重的性能问题，所以 Python 官方没有采用这个方案，而是采用了 GIL（主角登场了）。GIL 的思路很简单：与其对多个对象上锁，不如只对解释器上一个锁，有效避免上多个锁的问题。对于 Python 官方来说，既然已经采用了简单的方法实现 gc，那也采用简单的方法解决引用计数的竞态冲突问题是很合理的，当然，代价就是 Python 的多线程无法实现并行。\n在当年来说，使用 GIL 并没有什么问题，可是当 Python 逐渐被用于后端开发后，不少开发者都开始抱怨 GIL，而且正好 Python3 带来了一堆不兼容 Python2 的改变，为什么此时不干掉 GIL 呢？\n去除 GIL 有很多种办法，例如更改 gc 的实现，使其不再依赖引用计数，或者采用其它解决引用计数的竞态冲突问题的方案，等等。可惜的是，这些方案要么太难以实现，要么会降低单线程应用和多线程 I/O 密集型应用的性能，所以移除 GIL 并不简单。\n除此以外，还有一个原因，那就是我们提到 Python 的优点时经常列举的一点：Python 可以轻易集成使用 C/C++ 语言编写的库，它们极大丰富了 Python 的生态，调用这些库时也不用担心性能问题。虽然这些 C 库铸就了 Python 的辉煌，但也存在一个问题：这些 C 库本身不一定是线程安全的，在多线程环境下可能会出现各种奇怪的问题，这点应该不少用 C 语言写过应用的人都深有体会，要想兼容这些线程不安全的 C 库，GIL 是最简单（也许是唯一）的方案。\nPython 的多线程真的没用吗 虽然大家都在吐槽 Python 的多线程约等于单线程，但其实在某些情况下 Python 的多线程依然是有用的。首先我们需要区分 I/O 密集型应用与计算密集型应用这两种情况，前者经常等待 I/O 操作，例如读写数据库，上传/下载文件，后者在运行时会消耗掉所有分配给它的 CPU 资源进行计算，例如图像处理。\n对于计算密集型应用来说，Python 的多线程反倒是一个累赘：\nimport time from threading import Thread COUNT = 50000000 def countdown(n): while n \u0026gt; 0: n -= 1 t1 = Thread(target=countdown, args=(COUNT//2,)) t2 = Thread(target=countdown, args=(COUNT//2,)) start = time.time() t1.start() t2.start() t1.join() t2.join() end = time.time() print(end - start) import time COUNT = 50000000 def countdown(n): while n \u0026gt; 0: n -= 1 start = time.time() countdown(COUNT) end = time.time() print(end - start) 实际运行后会发现上面的多线程版本居然比单线程要慢一点，原因就是多线程不能并行，与单线程相比，多线程版本中线程间的上下文切换还浪费了一些时间。\n那么 I/O 密集型应用的情况呢（使用 time.sleep 模拟 I/O 操作）：\nimport time from threading import Thread def fake_io(n): time.sleep(n) t1 = Thread(target=fake_io, args=(2,)) t2 = Thread(target=fake_io, args=(2,)) start = time.time() t1.start() t2.start() t1.join() t2.join() end = time.time() print(end - start) import time def fake_io(n): time.sleep(n) start = time.time() fake_io(2) fake_io(2) end = time.time() print(end - start) 这回多线程版本大获全胜，仅用了约2秒结束运行，而单线程版本用了约4秒。\n看到这里，有些同学可能有点奇怪，为什么此时多线程看上去像是没有 GIL 那样以并行状态运行，只用了2秒就结束。其实这里并没有并行，Python 始终只使用了一个 CPU 核心，只是 Python 对 I/O 操作做了一个优化：当进行 I/O 或 time.sleep 这样会阻塞当前线程的操作前会主动释放 GIL，自己等待导致阻塞的任务完成，由于 GIL 被释放所以其它的线程能够运行，完成后该线程再获取 GIL。这个优化并不能实现并行，因为在同一时刻依然只有一个单位在工作，但得益于它，Python 的 I/O 密集型应用在多线程下的表现要比单线程好。所以，Python 的多线程并不是完全没用的。\n为什么依然需要线程锁 当我第一次知道 Python 的 GIL 对多线程的影响后，就产生了一个挥之不去的问题：既然都有 GIL 了，为什么多线程编程还需要上线程锁呢？现在想来，我应该是被相关文章里的“Python 多线程约等于单线程”这个说法给误导了：既然等于单线程，那就不需要用于多线程的线程锁吧？本质上来说，这属于对定义不够了解所产生的问题。从运行时的状态来说，即使采用了多线程编程，Python 在同一时刻也的确只有一个线程在运行，可是这并不代表我们可以忽略线程安全问题。如果对 GIL 和线程锁的定义和作用有足够的了解，那么就不会存在这个问题，显然，假如有了 GIL 后在多线程环境下可以不用线程锁，那 GIL 就必须提供与线程锁相同的功能。从这点出发，上文已经提到，GIL 是作用于解释器的，确保同一时刻只能存在一个线程，而线程锁作用于多线程编程里的临界区，或者说是对应代码里的共享数据，确保不会发生竞态冲突。前者并不能实现后者的功能，举个多线程下的例子：\nimport threading n = 0 def foo(): global n n += 1 threads = [] for i in range(100): t = threading.Thread(target=foo) threads.append(t) for t in threads: t.start() for t in threads: t.join() print(n) 有时候这段没有使用线程锁的代码不一定能输出100这个值，具体原因就是 GIL 并不保证执行完成一个线程里的操作后才切换到另一线程，也就是说不加线程锁可能会出现：线程 A 读取了变量 n（假设此时是 10），线程 B 读取变量 n（此时是 10），线程 B 修改了变量 n（n = 10 + 1），线程 A 修改变量 n（n = 10 + 1）。此时线程 A 对变量 n 的修改会导致错误的结果（它修改的是过时的值）。这与其它语言中的线程安全问题是相似的，Grok the GIL: How to write fast and thread-safe Python 一文从原子操作的角度解释了为什么 Python 依然需要线程锁。\n尽管仍然需要线程锁，但是 GIL 还是为 Python 多线程编程带来了一个好处：无需像其它语言那样考虑锁的颗粒度，上粗颗粒度的锁并没有任何问题，只需确保上线程锁的那部分代码不存在 I/O 等会释放 GIL 的操作，不然的话会导致性能下降，原因是：在当前线程进行 I/O 时，GIL 被自动释放，一般情况下会自动切换到另一线程，但是如果此时线程锁未被释放，那将导致另一线程无法进入临界区，不得不等待持有线程锁的线程完成 I/O。\n如何实现并发 在存在 GIL 的情况下，该如何实现并发编程并且让 Python 能在同样的时间内处理更多的事情呢？大致有以下几种思路。\n多线程/协程 之所以把多线程和协程放在一起，是因为这两者都无法实现并行。协程（Coroutine）也是在遇到 I/O 等阻塞操作时主动让出 CPU 的控制权让其它协程能够运行，思路都是让 CPU 单核不要浪费时间在等待阻塞操作上，只不过与多线程相比协程的花销更小，现在越来越多的强调性能的 Python 框架开始采用协程，如 FastAPI、HTTPX 等。历史上 Python 存在多种实现协程的方式，如 Gevent、yield 等，现在 Python 官方推荐的是通过 async/await 关键字实现。这两者都适合在 I/O 密集型应用中使用。\nimport asyncio import time async def say_after(delay, what): await asyncio.sleep(delay) print(what) async def main(): task1 = asyncio.create_task( say_after(1, \u0026#39;hello\u0026#39;)) task2 = asyncio.create_task( say_after(2, \u0026#39;world\u0026#39;)) print(f\u0026#34;started at {time.strftime(\u0026#39;%X\u0026#39;)}\u0026#34;) start = time.time() await task1 await task2 end = time.time() print(f\u0026#34;finished at {time.strftime(\u0026#39;%X\u0026#39;)}\u0026#34;) print(\u0026#39;Time taken in seconds -\u0026#39;, end - start) asyncio.run(main()) 多进程 这是能让 Python 实现并行的一个方案，原因是 GIL 是针对单个解释器的，既然如此，多开几个解释器不就能同时运行多个工作了吗。当然，考虑到进程上下文切换的代价要比线程大，这个方案比较适合计算密集型应用。\nPython 内置的 multiprocessing 库提供了对应的支持。值得一提的是，《七周七并发模型》的第三章“函数式编程”中提到 Clojure 语言提供了 pmap 函数实现对 map 的并行化，Python 通过进程池也可做到这点：\nimport multiprocessing from multiprocessing import Pool def f(x): return x * x with Pool(multiprocessing.cpu_count()) as p: print(p.map(f, [1, 2, 3])) 用 C 语言重写耗时的代码 最后的杀手锏，嫌弃多进程消耗资源大又想并行怎么办，答案就是把相关代码用 C 语言重写。C 库中的代码并不受 GIL 限制，而且一般来说 C 语言编写的代码执行速度要比 Python 快不少，还可以充分利用 CPU 的并行能力（如 SIMD），像 NumPy 这种科学计算库就是很好的例子。虽然性能很诱人，但是用 C 语言重写其实是一个非常麻烦的事情，没有足够技术力的情况下最好不要考虑这个方案。\n结语 Python 的 GIL 给想要实现并行的程序员带来了一定的挑战，同时由于 Python 作为解释型语言的先天劣势，其性能在面对短时间内高流量的情况时有些无力，当然，虽说如此，不少能人还是探索了相当多的解决方案，使得 Python 的性能不至于太差，让 Python 在后端开发中依旧占据一席之地。\n当然，如果你实在受不了 GIL，还可以考虑使用其它语言的 Python 实现，只是，是否能使用 C 库和不同实现的细节差异所带来的坑使得并没有什么人选择这样做，改用其它语言的后端框架也是一种选择。当对高性能有所要求时，不要为难自己，换一门语言海阔天空。\n","date":"2021-05-08T00:00:00Z","image":"https://viflythink.com/Python_GIL_and_concurrency/show_hub685971fcaff719029f241cd147356bf_356637_120x120_fill_q75_box_smart1.jpg","permalink":"https://viflythink.com/Python_GIL_and_concurrency/","title":"Python GIL 和并发编程"},{"content":"半年以来的第一篇新博文！九月底的时候放弃考研，然后尝试的秋招都凉了，处于颓废期的博主正好看到第七届中科大信息安全大赛（Hackergame 2020）即将举办，于是便去参加这个 CTF 比赛转换心情。作为一个非信安专业的学生，这是我第一次参加信息安全大赛，虽然之前也看过往年中科大信息安全大赛的题解，但自己真正参与时才发现自己与专业人士的差距。专业 CTF 选手轻松占据了排行榜前列，不过本菜鸡也玩的很开心，打完比赛后不得不说比赛的题目设置都相当有趣，对信安有点兴趣的人来这个比赛玩玩保证不会后悔。\n很菜的只拿到了 800 分，但下面还是写一下成功解决的题目的题解吧。\n签到 为了鼓励参与而设置的送分题，既然是 Web 类的题目那先在浏览器按 F12 打开开发者工具准没错，随便拉一下，点击提取，果然不能拿到 flag，不过看到浏览器发送了一个 GET 请求，其中的参数 number 就是刚才拉到的数字。\n 尝试获取签到题的 flag \n那么我们试试提一个 flag 吧。把 number 参数的值改为 1，就成功拿到签到题的 flag 了！\n 成功获取签到题的 flag \n猫咪问答++ 这题很明显是考验参赛者使用搜索引擎的能力。不过嘛，看到 2018 年猫咪问答题解后我想到一些题目也可以靠脚本暴力尝试进行破解，第一和第四小题搜索起来都比较麻烦，所以这两题就靠脚本破解好了。\n第二小题的答案可以在RFC1149 文档上找到，原文是“A typical MTU is 256 milligrams.”，所以答案是 256。\n第三小题的答案可以在中国科学技术大学 Linux 用户协会新闻站上找到，原文提到“最后一项是李文睿同学介绍了开源游戏 Teeworlds”，所以得到 9 这个数字。\n第五小题的答案依然可以在中国科学技术大学 Linux 用户协会新闻站上找到，答案是 17098。\n对于第一小题，我先通过粗略估计得出答案至少为 6 的结论，接着就是毫无技巧的脚本暴力破解时间，最后得出第一小题答案是 12，第四小题答案是 9。\n2048 非常有趣的 2048 游戏，但是，既然这是打 CTF，那这题肯定不是考验我们玩 2048 的技术，首先像签到题那样胡乱尝试直到在开发者工具看到一个 GET 请求：\n 尝试游玩 2048 \n看来这题想要取得 flag 就需要找到出题者喜欢的水果，虽然可以靠脚本暴力尝试所有常见的水果名，不过通过分析网页源代码我们可以找到 2048 获胜时将会发送的网络请求：\n 2048 的源代码分析 \n好，水果名就藏在其中，只需在开发者工具的控制台里输入 (\u0026lsquo;b\u0026rsquo;+\u0026lsquo;a\u0026rsquo;+ +\u0026lsquo;a\u0026rsquo;+\u0026lsquo;a\u0026rsquo;).toLowerCase() 就能得到“banana”这个答案了（神奇的 JavaScript 语法），发送这个网络请求即可获得 flag。\n 获得水果名称 \n一闪而过的 Flag 在 Windows 下双击下载的 exe 文件发现黑窗一闪而过，那么很自然的想到在 exe 文件所在的目录下按住 Shift 键并点击右键选择“在此处打开 PowerShell”，输入 ./Untitled01.exe，然后可执行文件就输出了 flag{Are_you_eyes1ght_g00D?_can_you_dIst1nguish_1iI?} 这个答案（我还以为会有其它障碍）！本题难度非常低，基本上在终端里执行过可执行文件的人都知道先尝试这样做。\n从零开始的记账工具人 中文大写数字转阿拉伯数字？这个需求想必很常见吧。我找到了一个能实现这个功能的 Python 库，接下来就是写一个脚本来帮我们进行计算了。\n为了减少工作量（懒得写读取 xlsx 文件的代码），我用 MS Excel 导出文本文件，然后进行计算。\n 导出的账单文件 \n写脚本时需要注意 Excel 导出的 txt 文件采用的是 GBK 编码。根据计算结果得到 flag{11118.23}。\n233 同学的 Docker 注意到题目描述里说明“写了一行命令删掉这个文件”，对 Docker 有点了解的人应该已经想到这个文件至少在某一层依然存在。\n首先尝试使用 Docker history 回滚到未删除 flag.txt 文件时的版本，执行 docker history 8b8d3c8324c7/stringtool 后输出：\nIMAGE CREATED CREATED BY SIZE COMMENT be6d023618d1 2 weeks ago /bin/sh -c #(nop) ENTRYPOINT [\u0026quot;/bin/sh\u0026quot; \u0026quot;-c… 0B \u0026lt;missing\u0026gt; 2 weeks ago /bin/sh -c rm /code/flag.txt 0B \u0026lt;missing\u0026gt; 2 weeks ago /bin/sh -c #(nop) COPY dir:c36852c2989cd5e8b… 1.19kB \u0026lt;missing\u0026gt; 6 weeks ago /bin/sh -c #(nop) WORKDIR /code 0B \u0026lt;missing\u0026gt; 6 weeks ago /bin/sh -c mkdir /code 0B \u0026lt;missing\u0026gt; 6 weeks ago /bin/sh -c #(nop) ENV PYTHONUNBUFFERED=1 0B \u0026lt;missing\u0026gt; 6 weeks ago /bin/sh -c pip3 install pipenv 37.5MB ... 这里执行的 rm /code/flag.txt 就是题目所说的删掉了 flag.txt，然而除了最新的 tag 外其它层的 ID 都是 \u0026lt;missing\u0026gt;，看来上面的教程并不适用。不过没关系，这里还有一篇教程教你如何寻找机密信息。执行 docker save 8b8d3c8324c7/stringtool \u0026gt; out.tar 得到 dump 出来的文件。解压 out.tar，在 a39ee53cb7d2d86ef0\u0026hellip;（省略）这个文件夹下解压 layer.tar 即可得到 flag.txt。\n狗狗银行 不得不说这题难倒我几天了，看完规则就可以确定在正常情况下我们绝对赚不到钱，想要让净资产达到两千以上只能靠寻找漏洞了。刚开始时我以为需要用到整数溢出，没想到前端还对转账数额上限进行了限制，那就靠 F12 找到网络请求刷吧。没想到虽然网页显示的净资产已经超过 2000，但还是没法取得 flag。接着我又尝试了负数，浮点数等各种奇怪的输入，都没有办法取得成果，我被题目卡住了。\n直到两天后组委会发布公告（仅截取重要内容）：\n 公告 1：本题前端计算存在浮点数导致的计算误差，数字特别极端时显示可能不正确。但后端采用大整数精确计算，只有净资产确实高于 2000 时才会给出 flag。\n  公告 3：本题新增限制：每个用户最多 1000 张卡，每张卡最多 100000 条交易\u0026hellip;\u0026hellip;\n 嗯\u0026hellip;公告 1 直接说明我之前的解题思路不对，不过公告 3 倒是给了我灵感：本题需要开多张卡才能解决。那么，也许是利息计算存在误差？我先做了一个测试，得出一张储蓄卡需要至少 167 元才能获得 1 元的利息这个结论。注意到储蓄卡的规则是“利率每日 0.3%“，1 / 0.003 = 333.33，也就是说正常情况下应当存入 334 元才能获得 1 元的利息，但这里只需 167 元即可。然后让我们看看信用卡的规则：利率每日 0.5%，最低 10 元。那么在每日增加 10 元负债的情况下我们最多能从一张信用卡中拿到多少钱呢，答案是 2099 元。2099 / 167 = 12.5689，这意味着我们终于发现了发家致富的好办法，因为此时从信用卡获取的贷款居然能给我们带来比负债利息更大的收益。 于是具体的赚钱方法就是：开一张信用卡，然后开 12 张储蓄卡，用信用卡给每张储蓄卡转帐 167 元，那么我们每日的净收益就是 12 - 10 = 2 元。不停重复上述步骤直到题目规定的上限，然后吃饭结束一天。具体代码可通过gist 查看。运行脚本后打开网页可看到 flag{W0W.So.R1ch.Much.Smart.52f2d579}。\n 成功获取狗狗银行的 flag \n一些没做出来的题目 先说一说令我觉得遗憾（感觉差点就能做出来）的题目吧。看了官方/非官方题解后，不得不说有些题目真的只是差一点就能做出来了，请容我在这里倒下苦水。\n“从零开始的 HTTP 链接”，我已经找到一篇文章提到 curl 可以连接零号端口，然而 Arch 上的 curl 版本过高，没法做到这一点，本博主居然忘了自己可以编译一个旧版本的 curl 尝试连接，错失了这一道题。除了 curl 外，这题也可以通过 Python 解决。\n“来自一教的图片”，作为一个学过图像处理的人士，居然没想到可以使用 np.fft.fft2 得到答案，真是非常惭愧啊（狗头保命）。\n“生活在博弈树上”，虽然知道可以靠 C 语言 gets 函数的安全缺陷进行栈溢出攻击跳转到输出 flag 的位置，但是不会构造 payload，所以只能放弃这题。\n除了上面这些让我遗憾的题目外，还有一些有趣的题目值得一提。\n“室友的加密硬盘”，什么，居然有 512 位 AES 加密？看完题解后发现这不是重点，并不需要猜测这里的加密实现是否存在缺陷，使用冷启动攻击才是正道。这也提醒我们全盘加密并不能 100 % 确保数据不会泄露，遇到懂得在 dump 的内存中寻找密钥的攻击者还是有可能被破解的。\n“超简易的网盘服务器”，很有趣的一点是这题与上一题产生了联动，数据放本地不安全，那么放在云端就能确保万事大吉了吗？为了解决这题我特意去研究了 Nginx 的 location 匹配规则，虽然得知针对本题的 nginx.conf 访问 php 文件可以绕过认证，但对于如何访问 private 文件夹下的 flag 还是一筹莫展，尝试了 ../../ 这样的路径，但可惜 h5ai 并没有这么容易被攻破。比赛结束后发现自己吃了没认真阅读 h5ai 源代码的亏，没想到在没认证的情况下可以通过 h5ai 的下载功能把全部文件下载。不得不说，这题成功吓到了我，让我也赶快去检查自己的 Nginx 配置，避免出现同样由于忽略匹配优先级而导致的漏洞。\n总结 谢谢中科大信息安全大赛，让我体验到了久违的解决问题的乐趣，我已经很久没体会过躺在床上时依然在思考比赛题目的感觉了，这次比赛成功做到了这点，对我来说这就足够了。名次并不重要，重要的是解题的乐趣。\n如果明年还有中科大信息安全大赛，那我肯定会参加，当然，与今年没什么准备就仓促上阵不同，至少我会先看下 CTF Wiki 再来解题，争取更好的名次。也强烈安利各位还没参加过 CTF 的童鞋尝试一下中科大的信息安全大赛，并不需要多少专业技能也可解题，既可以体会到这种充满乐趣的过程，顺便还能学到一点冷门的东西。\n","date":"2020-11-09T00:00:00Z","image":"https://viflythink.com/Hackergame_2020_writeups/show_hu047d013128609b76bc4f6f1998ad3a88_1069728_120x120_fill_q75_box_smart1.jpg","permalink":"https://viflythink.com/Hackergame_2020_writeups/","title":"中科大信息安全大赛初体验"},{"content":"2021.2.2.更新：受 Aloxaf 的博文启发新增使用自己的 PKGBUILD 进行构建的说明。\n尽管目前博主我还在考研，但最近还是经不住折腾 Arch 的诱惑，抽空对使用 Arch 以来一直觉得体验不够好的安装 AUR 软件包流程进行改造，最终的结果就是搭建了这一个自动化的 AUR 编译打包下载安装一条龙服务，并写下本文向各位安利。要问为什么我想折腾这个东西，当然是因为使用 AUR 助手安装 AUR 的软件包存在如下缺点：\n 下载速度慢，由于很多时候都需要从 GitHub 下载文件，所以每秒 10 KB 的下载速度是很常见的（虽然这点可以通过设置 http_proxy 环境变量让 Yay 等 AUR 助手使用代理来解决） 编译需要时间，如果你只是需要几个小软件包那可以无视这点 给别人分享已打好的软件包有点麻烦，每次更新你都需要通过某种方式传输文件给对方（凑够三点 ／人◕‿‿◕人＼）  为了解决以上问题，本文使用免费的 GitHub Actions 与 Cloudflare Workers，手把手教你搭建一个自动化 AUR 软件构建流程，只需一次配置，你就可以享受船新的白嫖 AUR 使用体验。另外，这也是我第一次实际使用 CI（持续集成），通过配置整个工作流，我算是学习了一把 CI 的使用（PS：这才是真正的目的），所以你也可以把这篇文章当作我的 CI 学习笔记。\nGitHub Actions 简介 首先，GitHub Actions 是 GitHub 在 2019 年推出的一项 CI 服务。如果你没听说过 CI，那这里我尝试用一句话来解释，CI 就是对新的项目更改进行自动化构建，在本文的场景下，新的更改指的是 AUR 上的 PKGBUILD 文件发生变更（实际上我为了偷懒，选择了设置定时任务而不是监测 PKGBUILD 的变更），自动化构建就是自动编译加打包以及上传（如果是闭源软件那就不是编译而是拆包等操作）。嗯，就是这么简单，如果想知道 CI 的详细定义，可以看下红帽的文章。\nGitHub Actions 的特点是支持的触发条件种类数非常多，而且与 GitHub 的集成很好，学习难度也不高，只要简单地写一个配置文件即可，还可轻松调用别人写好的操作步骤，对于开源项目作者来说最大的好处就是可以白嫖 GitHub 的机器用来为不同的平台编译。如果你已经对 GitHub Actions 感到心动，那么不妨阅读官方文档来学习一下用法，或者靠阮一峰的介绍文快速上手。想要更简短的介绍？没问题，来看看下面的讲解吧。\n想要使用 GitHub Actions，那首先需要在项目根目录下的 .github/workflows 文件夹下创建一个以 yml 为后缀名的 workflow 文件（如 build.yml），在这个 YAML 文件中写入我们的配置。那么配置该怎么写呢，让我们看一个示例：\nname:Greeting from Monaon:pushjobs:# ================== 第一个 job，这只有一个 job ==================my-job:name:My Jobruns-on:ubuntu-lateststeps:# ================== 第一个 step，执行单个命令 ==================- name:Print a greetingenv:MY_VAR:Hi there! My name isFIRST_NAME:MonaMIDDLE_NAME:TheLAST_NAME:Octocatrun:echo $MY_VAR $FIRST_NAME $MIDDLE_NAME $LAST_NAME.# ================== 第二个 step，使用别人的 action ==================- uses:actions/checkout@v2# ================== 第三个 step，执行多个命令 ==================- name:Install the dependenciesrun:|sudo apt-get update sudo apt-get install pkg-config gettext按从上到下的顺序来看，name 对象应该无需解释了，值得注意的是 on 对象，可以填入单个事件或事件数组作为触发条件，当满足条件时便执行这个 YAML 文件里的内容（一个项目可以存在多个 workflow 文件），在示例中的 push 指的是 git push，即每次推送代码都会触发这个 workflow，完整的事件支持列表可通过官方文档获知。\n接下来就是 jobs 了，在这里我们只创建了一个名为 my-job 的 job，一般而言 jobs 是 workflow 文件的主体，一个 job 由若干个 step 组成，这些 step 会按顺序执行，为了便于阅读，我用分割线将各个 step 分开了。\n在解释 step 前我们不妨先看下每一个 job 中都要填写的 runs-on 对象，它指定了该 job 的工作系统环境，目前可选的系统有 windows-latest、ubuntu-latest、ubuntu-16.04、macos-latest，这覆盖了主流的操作系统平台，为不同平台的编译提供了便利。\n最后，就是每个 job 中必须存在的 step 了，每个 step 都代表一个单独的操作步骤，既可以在 run 对象内填入你需要执行的 Shell 命令，也可以在 uses 对象里填入对应的配置以使用别人的 action（在 Marketplace 中浏览全部 action）。env 对象用来设置环境变量，这个对象存在一个非常有趣的应用场景：如果你的 step 需要使用不宜公开的 Token，那你可以在项目设置中设置该 Token，然后在 env 对象中使用 super_secret: $ 将这个 Token 设为一个环境变量，并在自己的 step 中读取该环境变量以取得 Token，这样就能避免在 workflow 文件中硬编码 Token。当你再次看到 $ 这样的变量时，你就应该明白这是一个私密变量，是不能公开的。\n开始构造打包工作流 经过上文的介绍，各位应该对 GitHub Actions 有了一定的了解，接下来就让我们开始白嫖 GitHub Actions 吧。为了白嫖，我们需要先创建一个新的 GitHub 仓库，然后有两种方法创建 GitHub Actions 配置文件，第一种方案是在这个仓库创建 .github/workflows 文件夹，在这个文件夹下新建一个 YAML 文件（完整路径示例：.github/workflows/build.yml）；第二种方案是在仓库的 Action 页面按照指引随便新建一个。完成这个步骤后就可以根据下面的指导在 YAML 文件中配置 GitHub Actions 了，不想看详细配置过程的话可以跳到下方直接抄配置。\n自动编译 AUR 的软件包 一般而言，我们都是在 Arch Linux 上构建 AUR 上的软件包，但是上文提到的 runs-on 对象可以填入的系统并不包括 Arch，那该怎么办呢？答案是使用基于 Arch 的容器，在容器内构建。这里要感谢 Qv2ray 的一位开发者 DuckSoft 提供了这个思路，而且编写了 build-aur-action 这个 action 用来编译打包 AUR 上的软件。现在，我们需要考虑的就是如何自动进行编译，从 CI 的正常使用方式来说，我们应该在 on 对象中设定这样一个触发条件：当 AUR 特定的软件包更新时自动进行编译。不过这个方案还需要写检测更新的代码，为了偷懒，我选择设置定时任务来编译，由于 on 对象支持通过 Cron 语法设定定时任务，所以这个问题能被轻松解决。就这样，我们完成了一个简单的 workflow 文件：\nname:BUILDon:schedule:- cron:\u0026#39;1 */8 * * *\u0026#39;jobs:build:runs-on:ubuntu-lateststeps:- uses:DuckSoft/build-aur-action@masterwith:repo-name:osu-lazer提醒一下，使用别人的 action 时可能需要使用 with 对象输入一些变量，在这里我们输入的就是想要构建的 AUR 软件的软件包名。\n上传到 GitHub Releases 在上一步中我们已成功地构建了想要的软件包，接下来需要解决的就是如何把软件包取出来这个问题了。最好的解决方案莫过于将构建出来的软件包上传到 Releases，GitHub 官方提供了 upload-release-asset 来完成这个操作，但我看了说明文档后觉得这个太麻烦了，它不支持通过 Unix 终端规则（例如 “*.zst”）筛选要上传的文件，而且需要先创建 Releases 后才能上传文件。经过一番谷歌，我找到了 release-action 这个替代品，与 upload-release-asset 相比，这个 action 的配置明显更简单，从下面这段配置即可看得出来：\n- uses:ncipollo/release-action@v1.7.3with:allowUpdates:truetag:\u0026#34;packages\u0026#34;artifacts:\u0026#34;./*/*.zst\u0026#34;token:${{ secrets.GITHUB_TOKEN }}把这段配置添加到 workflow 中，然后我们先看看 with 对象中输入的变量。token 是上传文件到 Releases 时必需的一项变量，从它的形式就可以看出这是一个私密变量，不过这个私密变量是内置的，我们不需要在项目中手动设置这个变量，直接使用即可；接着就是 tag 了，为了方便管理，我们在仓库的 Releases 页面创建一个 tag，然后将 tag 的名字填入其中。完成配置后这个 action 就会把构建的软件包上传到指定 tag 下的 Releases，我们也可以下载该软件包了。\n使用 matrix 进行改进 虽然目前我们的 workflow 已经能用了，但是需要编译多个 AUR 的软件时需要多次复制粘贴上面的 step，这可太难看了，是否存在更优雅的方法呢？答案是有的，经 DuckSoft 的提醒，可以使用 matrix，它基于单个 job 中定义的 steps 并行运行多个 job，多个 job 之间的差异就是特定变量的差异，这些变量以数组的形式存在。一般来说，matrix 的用处就是为不同平台采取同样的步骤进行构建，在本文的场景下就是采用同样的步骤构建不同的 AUR 软件。虽然听着有点抽象，但看一下这个例子你就应该能明白了：\njobs:build:strategy:matrix:repos:[osu-lazer, mpv-mpris]fail-fast:falseruns-on:ubuntu-lateststeps:- uses:DuckSoft/build-aur-action@masterwith:repo-name:${{ matrix.repos }}与之前的 workflow 不同，我们先创建了 repos 数组，并在其中填入需要构建的软件名。如果不把 fail-fast 设置为 false，在并行 job 中出现一个运行失败的 job 时会导致其它的 job 被终止。另外，使用 build-aur-action 时我们没有直接输入 repo-name，而是以 $ 的形式输入，数组中的变量会自动应用到对应的 job 中。\n使用自己的 PKGBUILD（可选） 上述版本已经很完美了，不过还存在一个问题：我需要的某个软件包虽然在 AUR 中存在，但对应的 PKGBUILD 写的太烂了/无法构建成功，此时我写了一个 PKGBUILD，希望能白嫖 GitHub Actions 进行构建，该怎么办呢。这个需求也是早有人想到了，只需使用 pkgbuild-action 就可解决，它还可以解决打的包还依赖了其它的 AUR 包的问题。为此，我们需要再添加一个 job，checkout 目前仓库获取 PKGBUILD，然后使用 pkgbuild-action 进行构建，需要的 pkgdir 参数就是 PKGBUILD 所在的路径（父文件夹），最后依然是使用 release-action 根据 pkgbuild-action 返回的构建产物路径将其上传到 GitHub Releases。\n最终成品 最终版的 workflow 可以在这查看，只需 fork arch-build，然后按下面的说明修改一下 workflow 文件即可食用。注意，经过一段时间的改进，最终版的配置已与上文存在一定区别，其中的 uploadToOneDrive 是《使用 Vercel 与 OneDrive 自建软件源》中所需的 job，如果你不需要建立一个可公共访问的软件源请删掉它。\n如果只是需要构建上传 AUR 包，那只需修改 buildAUR 这个 job 中的内容，根据自己的需要修改其 matrix 内的软件包名，buildNonAUR 的内容则可以删掉；如果想使用自己的 PKGBUILD 进行构建，那还需要修改 buildNonAUR 这个 job，依然需要修改其 matrix 内的软件包名，另外还需要在仓库的根目录下新建以软件包名命名的文件夹，在其中存放对应的 PKGBUILD 文件和其它构建过程中所需的资源文件。\n到此为止，借助 GitHub Actions，我们拥有了一个 24 小时可用的编译机以及公开的软件包存储库，解决了本文开始提到的第二与第三点问题。这些都是全自动且免费的，为了更好的体验，下文将介绍如何让安装软件包也实现自动化。\n简单的自动更新仓库 打开浏览器，从 Releases 页面下载软件包，然后执行 pacman -U xxx.pkg.tar.zst 安装软件包，这些操作实在太麻烦了，为何不建立一个软件源，令每次执行 pacman -Syu 时自动安装最新版本的软件呢。自建软件源听上去十分高大上，但其实只是建立一个本地软件源并不难，Arch WiKi 几段文字便说明白了，当然，如果想建立一个在线的公用软件源会麻烦一些，所以这里只说明如何建立一个自动更新的本地软件源。想要建立公用软件源的话请跳过下文，阅读我的新博文《使用 Vercel 与 OneDrive 自建软件源》。\n使用自动化脚本 作为一个爱偷懒的人，我肯定希望能自动化下载软件包与更新软件仓库的操作，为此我写了一个脚本来完成这些事情，各位只需打开项目地址，下载代码并根据说明进行操作即可。我在这里说明一下 conf.py 的配置：UserName 和 GitHubRepoName 并不难理解，举个例子，我的白嫖仓库地址是 https://github.com/vifly/arch-build ，那么需要填写的 UserName 便是 vifly，GitHubRepoName 则是 arch-build；ProxyURL 在下一小节会提到，这里先不说；DownloadPath 是从 Releases 下载的软件包的存储路径；末尾的 ArchRepoDBPath 和 ArchRepoName 是用于生成本地软件源的数据库的，脚本会调用 repo-add 根据 DownloadPath 中的软件包生成路径为 ArchRepoDBPath/ArchRepoName.db.tar.gz 的数据库。\n当你成功运行脚本建立了一个本地软件源后，还需要修改 /etc/pacman.conf 文件，在末尾添加以下配置以让 Pacman 同步你的软件源的数据库（自行替换 ArchRepoName 与 ArchRepoDBPath）：\n[ArchRepoName] SigLevel = Optional TrustAll Server = file://ArchRepoDBPath  另外，为了让本地的软件仓库保持最新，我们可以通过 Cron 设置一个定时任务自动运行这个脚本。现在，我们得到了一个完全免费、自动更新的个人软件仓库，快执行 pacman -Syu 开始享受白嫖的快乐吧。\n使用 Cloudflare Workers 反代加速下载（可选） 为了解决在国内 GitHub 下载速度慢的问题，让我们继续发扬白嫖的精神，使用 Cloudflare Workers（不需要拥有域名） 来加快下载速度。广大白嫖党早已发现可以使用免费的 Cloudflare Workers 部署 serverless 应用反代国内无法访问的网络资源，在这里我们也使用这种方式加速下载。刚开始时我使用了 gh-proxy 这个加速 GitHub 下载的项目，不过后来 Arch 群的 NickCao 同学推荐了他写的更通用的反代应用，感谢 NickCao，接下来我们便开始部署反代应用吧。 首先，打开官网，注册或登录你的 Cloudflare 帐号，点击 Start building，选择免费方案并创建一个专属的子域名（是 workers.dev 的子域名），进入主页后点击 Create a Worker，复制这份代码，像下图这样粘贴到编辑框内：\n 创建 Cloudflare Workers 应用 \n注意，页面中间的域名是 Cloudflare Workers 分配给你的一个专属子域名（形如 xxx.xxx.workers.dev），复制这个域名并用它替换左侧代码中的两处域名，完成修改后点击 Save and Deploy 保存并部署，这样我们就得到了一个可以反代网络资源的应用了。\n最后，还记得在上一小节中被忽略的 ProxyURL 配置项吗，这里各位只需填入刚刚得到的 xxx.xxx.workers.dev 域名就可以了，脚本会使用这个反代域名高速下载 GitHub Releases 的软件包。\n","date":"2020-04-28T00:00:00Z","image":"https://viflythink.com/Use_GitHubActions_to_build_AUR/show_hu3e4196b515918c37e47fce1bd97e68c0_760288_120x120_fill_box_smart1_3.png","permalink":"https://viflythink.com/Use_GitHubActions_to_build_AUR/","title":"GitHub Actions 打造 AUR 打包下载一条龙服务"},{"content":"我在博客的简介中说过这个博客会记录我的折腾与感想，不过到目前为止，本博客的归档里全都是技术折腾类的文章。对于我来说，写折腾记录是一件比写论述文章轻松的事情，后者需要具有明确的写作目的与结构安排，而且通用性更广，而前者则不需要管这么多。虽说如此，我早就想写论述类文章了，毕竟能看到自己的想法以一种规整的形式出现在屏幕前是一种让人十分满足的事情。在好不容易战胜长期宅在家导致的拖延症后，我终于提笔写下了本博客的第一篇论述类文章（笑）。这里顺带说一下，本文标题化用自本人最喜欢的 RPG 《异域镇魂曲》中的一句话，原话是「时间不是你的敌人，永恒才是」。 虽然之前已经得知《永久记录》出版了，不过在这漫长的假期中，我才想到去阅读它。对我来说，这本书里的内容并不算新鲜，但对于很多我接触到的人来说，隐私是个很奇怪的问题，每次我想解释清楚时总发现三言两语是不足够的，既然如此，我就在此借《永久记录》来谈谈我对隐私的看法吧，废话就到此了，下面正式进入正文。\n不知道各位是否记得 2013 年的“棱镜门”事件呢，这与今天要说到的《永久记录》有着密切的联系。前段时间，“棱镜计划”等大型监视项目的揭露者斯诺登出版了这本名为《永久记录》的回忆录（由于内地出版社愚蠢地阉割了书中内容，斯诺登决定免费提供未经阉割的简体中文版本，下载请戳这，也可选择我在 OneDrive 上传的副本），在其中讲述了当年为何决定曝光一系列监视丑闻的动机，也讲述了紧张刺激的资料收集与逃亡过程。如果你还没看过这本书，那么我强烈建议你去把它看完，读这本书就像是读一个非常流畅的故事，只是与故事书相比最大的区别就是我们知道这是真的，而不是一个虚构故事（很多时候我更希望这只是一个虚构故事）。如果你还不清楚“棱镜计划”等项目是什么，没关系，下面是对此的一些描述。\n大规模监控项目 这一切也许源于所谓的总统监控计划（President’s Surveillance Program，PSP），其含糊的措辞给了情报机构极大的权力，特别是其允许国安局不必取得外国情报监控法院的搜查令便能实施监控，该计划的核心部分被称为 STLW（STELLARWIND，星风）。\nPSP 扫清了法律上的障碍后，就需要解决技术上的问题了。为了实现大规模监控，美国情报机构尽其所能与盟国的情报机构构建了两大网络监视计划：棱镜计划（PRISM）和上游收集（Upstream Collection），前者从谷歌、微软、苹果等服务商的云端所有内容中收集资料，后者从网络基础设施，如全球网络流量的转换器与路由器、经由太空卫星和高容量海底光纤电缆等地方直接抓取资料。\n棱镜计划的危险性应该无需说明，为了说明上游收集的能力，这里提供一个示例：在你打开（不加密的 HTTP）网站时，网络请求会经过国安局的“乱流”（Turbulence），其中有“混乱”（Turmoil）和“涡轮”（Turbine）两大组件，前者根据 metadata（元数据）判断该流量是否可疑，如果是，那么转给涡轮，涡轮会将合适的恶意程序注入到流量中以对你进行窃取信息的操作。\n总之，这些丧心病狂的项目可以用以下几句话概括：\n 无所不嗅，无所不知，无所不收集，无所不处理，无所不利用，无所不合伙。\n 至于收集到的信息是如何被使用的呢。为此存在着一个被称为“XKeyscore”的项目，情报人员可以通过该项目搜索到一个人的私人电邮、聊天记录、档案等等一切最为隐蔽的隐私资料，也包括目标的所有线上活动记录。\n为了实施这些项目，美国政府采用多种方式绕过法律和公众监督：\n 美国政府重新诠释“取得”（acquire）与“获得”（obtain）的定义：从原本描述情报资料进入数据库的过程，被扭曲成某人（或某个算法）未来某时刻查询并取得资料的行为。如此一来便大幅扩充了执法机关的权力。 令公众放下警惕的地方在于，情报部门记录的是 metadata 而不是实际的通信内容，这可以说是实际技术实力不足以储存所有内容导致的，但通过 metadata 也足以分析出一个人的具体行动（这只需要收集你昨晚入睡与今早起床的时间、每天逛了哪些地方、在哪里待了多久，以及你接触过的对象有谁，谁又与你联系过），而且获取与存储 metadata 的难度都是很低的。 美国国家安全局认为，你已经将手机里的记录“分享”给了“第三方”——你的电信商，因此你已经失去了宪法保障的隐私权。他们坚持认为，只有在分析师主动调查已经自动收集来的资料时，才算是搜查或扣押，而算法并不算。  觉得发生在美国的事情太遥远？来看看国内各大互联网公司的情况吧。还记得年底时各家公司推送的年度总结报告吗，这些年度报告都会告诉你你几点还在使用它们。看上去好像没什么，但这意味着它们记录了你的最晚使用时间，对于很多人来说，微信的最晚使用时间就等于准备睡觉的时间，最晚使用时间就属于上文提到的 metadata，除此以外，这些公司也详细记录了你的浏览行为（如在哪个页面停留了很长时间），诸如此类的信息足以勾画出一个人的行踪（无论是线上还是线下）与性格爱好，仅仅这点便足以让人感到不安了，而且这些信息看上去人畜无害，商业公司总是以“改善服务质量”为名收集这些信息，就算你阅读了隐私条款，也不会立刻想到收集的信息是如何被使用的，当然，也许单个公司收集的这些信息并不全面，并不足以将你的一切勾画出来，可是当政府能随意访问这些信息时，上面提到的全面画像就是轻而易举的事情，更别说政府还可以通过后门等访问你的通讯内容，在这种情况下，你的一切都暴露无遗。这是非常不幸的事情，互联网在飞速发展，但目前来说我们并没有迈向预想中的光明的未来，而是进入了接近于反乌托邦场景的监视资本主义。\n为什么隐私是值得重视的 对上文提到的情报机构无限制地侵犯个人隐私这一现状感到失望的斯诺登想要采取措施扭转这一局面，他选择了冒险进行公开爆料。我们都知道斯诺登此时在俄罗斯接受政治避难，美国政府暂时拿这位名人没什么办法，但在当时，斯诺登可不确定是否会被人发现他在收集机密资料，也不知道如何应对公开爆料后美国执法机构对他的拘捕。假如当年出了什么意外，那历史肯定会被改写。想到当年我对整个事件的看法无非就是，“哇，美国国安局居然有个牛人把这些事情抖了出来，且看美国这回怎么处理”，现在不由得为当时的想法感到羞愧。对于现在的我来说，当时的我只是抱有一种看热闹的心态，而完全不清楚曝光这种大项目的难度，也不清楚这样做的意义。时隔多年，当我通过这本书重温当年的事件后，才开始了解到了曝光监视项目的困难与意义。\n首先，让我们看看公开机密情报的难度有多大吧。若是没怎么关注此事，那你可能只会记得记者公开斯诺登提供的文件，而这些机密文件的获取难度则被忽视了，想当然的认为作为内部人员，泄密肯定不难吧。实际上，取得这些机密资料就等于潜入敌方情报机构窃取情报，作为窃取情报的能手，CIA 等部门肯定也会采取各种手段严防情报泄露。作为其中的雇员，斯诺登直接大规模查找这些信息肯定会被怀疑（内部肯定会有访问记录），而且，成功获取资料后还需要设法将其分批带出禁止携带存储设备入内的军事基地。就算取得足够的资料并带走，斯诺登还需要考虑如何将它们公布出去，这其中的资料太多了，让公众一个个翻阅肯定是一件不现实的事情，而且，斯诺登也不愿意牺牲美国的国家安全（斯诺登在书中明确说明自己是爱国的），所以他只能与记者合作对这些资料进行筛选并将筛选出来的与公众利益密切相关的资料公开，与记者的联络也是一个问题：需要考虑对方是否可信（道德与技术方面）。总而言之，历经九九八十一难后，这些文件才呈现在我们的面前。这些情节都可以在书中找到，部分甚至可以当作现实版的谍战小说来看，如果你还没读过，不妨现在去看看吧。\n上面提到公开爆料的风险是很大的，那么斯诺登为什么要冒如此大的险来公开信息呢？仅仅是对隐私受到侵犯的不满吗，在我看来，并不全是，按照书中的说法，斯诺登应是为了阻止大规模监控对美国的民主体制的侵蚀而挺身而出。有的同学可能会问，原本的主题不是隐私吗，怎么现在说起民主体制了。隐私与民主体制有什么关系呢，我们先理清这两者的关系吧。\n众所周知，美国的民主体制核心是三权分立，之所以这样设计，其原因就是为了实现分权思想，避免权力的膨大，对政府权力的限制，或许可以在“若无法律许可政府不能做任何事”这一句话中完全体现出来。美国情报机构的秘密的大规模监控项目很明显是不受约束的，它是秘密的，以至于不可能受到公众的监督和约束。另外，权力是会不断膨胀的，在斯诺登爆料前，情报机构只是拥有不受限制的收集隐私信息的权力，但是若没有人揭露这一问题，那么拥有这种能力的情报机构取得其它权力也不是不可能的事，举个典型的例子，在美国大选中各方总是会抨击对手的不良行为，假如情报机构向某一方提供对手的隐私信息（不一定是丑闻），那选举结果就会受到影响，情报机构的权力也能进一步扩大。能不受限制地进行监控等于拥有不受限制的权力，这样的存在无疑是对民主体制的一种威胁，这就是美国宪法中存在要求保障隐私权的条文的原因。《永久记录》提到了隐私与个人自由的关系，不过复述书中这部分内容并没有什么趣味，我就只说这个了。\n尽管如此，我猜不少人此时可能依然对隐私不以为意，“隐私这种东西我暂时也不需要，说这么多大道理也没用”，换句话说，既然隐私与我有关，那我愿意牺牲自己的隐私也是可以接受的？是否放弃隐私当然属于个人自由，但请注意，你是否在意隐私不仅会影响到自己的隐私，也会影响到别人的隐私，由于你不在意隐私而导致朋友或亲人的隐私信息泄露是可以接受的吗？\n 你可能因为怕麻烦而放弃此权利，或者你和多数人想法一样，认为只有做不光明的事才需要隐私保护。但是，声称自己不需要或不想要隐私，因为没有什么事好隐瞒的这种说法，是假定所有人都不该或不能隐瞒任何事情，比如他们的移民身份、失业历程、财务状况与健康记录等。你假定，所有人（包括你在内）都乐于与他人分享宗教信念、政党倾向与性生活，就如同有些人随意透露自己的电影、音乐品位与阅读偏好一样。\n 我强烈反对将自己的观念强加于别人身上的行为，即使不在意自己的隐私，也应当对别人保护隐私的行为保持最基本的尊重，这就是我反对在 Telegram 上称呼一些人是“隐私怪”这样的行为的原因，尽管我知道被称为“隐私怪”的那些人的确对隐私存在一定的误解以致于有时显得不合常理（也许其中一些人需要的是匿名），很多时候称呼别人为“隐私怪”也只是在开玩笑，但我们为什么要嘲笑保护隐私的行为呢？保护隐私并没有错，有错的只是对隐私的误解，若是能好好沟通的话，指出对方在哪存在对隐私的误解不是更好吗。\n即使仅看个人利益（假设不存在大型监控项目），隐私依然是一项值得重视的权益。很多人爱说“用隐私换取便利”，这说法隐含了隐私可以用来进行交易的含义，假如这是交易，那么我们不妨来衡量一下这其中的得与失。在拥有足够的个人信息的前提下，语音助手等产品能变得非常“智能便捷”，查天气、找联系人、操控智能家居，甚至网购下单，在方便的同时它也掌握了你的家庭住址、手机号码等敏感的个人信息，语音助手以外的服务也是同样的，当你欣然同意授权时是否想过这些信息若是被泄露会带来什么后果呢，我想诈骗份子肯定会非常高兴，而你对此并不会察觉到什么不对。在“交易”中光是不清楚自己到底付出了什么就已经很要命了，而且更重要的是，个人信息不是实体，实体若是被盗会很快被发现，但你难以察觉到个人信息是否被窃取，而当你后悔当初付出了隐私时，你也没法撤销这种“交易”。也请不要抱有太大的侥幸心理，认为个人信息被窃取是概率很低的事情，近年来经常出现的个人信息泄露事件就是很好的说明案例，而且即使发生的概率低，你也需要考虑到个人信息被泄露的后果，如果自认为后果严重，哪怕这种坏事的发生概率很低也应该有所准备，打个比方，个人信息泄露就像癌症，碰到它们的概率都很低，但若是真碰上了那会怎样呢。所以，下次打算“用隐私换取便利”前不妨先想想这点吧。\n从隐私到永久记录 仔细一想，隐私涉及的个人信息范围真广：从无论是谁都不希望泄露的身份证号码到绝大多数人不希望被看到的私人聊天内容，再到不起眼的 IP 地址，如果二十年前有人跟我说他能把这些信息全部收集起来，那我肯定会认为他在开玩笑；而在 2013 年，斯诺登告诉我们，美国的情报机构还真的可以做到这一点，他们花费了巨大的人力和物力来构建一个现代大型监控项目，无所不入地收集信息，还建立了一套完善的储存和搜索系统来使用这些信息，当然，这都是以打击恐怖主义的名义进行的。\n这一切的缔造者不仅包括政府部门，也包括了商业公司，他们互相勾结，构成了所谓的监视资本主义，在此环境下个人数据被当作宝贵的资源，大数据的作用被不断鼓吹，“智能”的服务背后是靠大量个人数据所堆积出来的效果，当然也少不了“国家安全”的需要，而用户甚至不明白这有什么问题。我们在网上的一切被通过各种途径所记录下来，政府与商业公司像对待金子一样小心地储存它们，生怕这些信息丢失，毫不客气地说，这些数据甚至有可能保存到人类文明尽头。我以前曾经想过，若是能把自己的数据长久地记录下来该多好，那样就可以随时回顾自己做过的事情了，现在，数据的确是被记录下来了，我们成为了“永恒”，但这些数据却不在自己的手上，而是在别人的存储设备当中，这些人能随意地翻阅你的信息，而你却毫不知情，不知道这是不是一件非常讽刺的事情呢。\n我们之所以在意隐私，就是因为想要在这监视资本主义下掌握自己的数据，无论这些数据是过去、现在还是将来。若是所有的数据都在我们无法控制的情况下被永久记录，从出生伴随到死亡，那意味着任何人都不应该犯下错误，因为你犯的错误会一直存在，没有“撤销”可言，成为人生中的一个污点并因此受到歧视。在我最悲观的预测中，大型监控项目继续发展所带来的未来就是这样一个害怕犯错的世界，想必那也是一个十分无趣的世界。\n个人信息的永久记录，这个看似科幻作品才会出现的场景如今已化作现实。上文我也提到了，信息被复制传播是一件难以察觉的事情，因此，即使你删除了某些信息，也没法确定在哪个地方是否依然保留了副本，当我们使用互联网时，信息不断产生，该如何让这些信息得到妥善的处理，这已经成为了一个大问题。此前我们从未想过数据竟有如此大的能量，也没想过数据能用来做那么多邪恶的事情，斯诺登的这本书之所以命名为“永久记录”，就是希望读者能认识到这一现实。即使我们暂时不知道这些信息的最佳处理办法，但我们至少知道以“国家安全”为由将其永久记录是一件错误的事情。我也希望各位读者能够花时间思考应该如何处理个人信息，因为：\n 雪崩时， 没有一片雪花觉得自己有责任。\n 总结 最后，作为一个注重个人隐私的人，我看完这本书后最大的感慨就是无论是保护个人隐私还是信息安全，人永远都是最重要的一环。美国固然有历史悠久的保护公民隐私的法律，可上文提到的这些人依然有办法绕开这个限制（通过混淆“取得”与“获得”的定义），稍微转换一下角度，对于想要保护自己隐私的人来说，只有自己重视隐私，投入一定的时间和精力，才能在当今这疯狂追求大数据的环境下有效保护自己的隐私，我们永远都不应该指望一两部法律能做到这一点，因为若没人确保法律的实行，那么法律就只是空谈。这也是本博客使用自建的 Matomo 统计分析服务和 Isso 评论系统的原因，只要愿意付出时间和金钱，总是会找到保护隐私的方案。我喜欢把“保护隐私”与“把事情做得更好”混为一谈，把事情做得更好需要付出额外的时间或金钱，保护隐私也是一样的，通过一定的付出，我们得以保护自己的隐私；另外，“把事情做得更好”与“保护隐私”同样属于思维方式，喜欢将工作完成的尽可能完美的人会在做事情时不由自主的想到如何把细节做得更好，而想要保护隐私的人想做一些事情时（如选择软件或服务、在社交媒体分享等）会自然而然的想到“这对我的隐私有什么影响呢”，所以无需担忧需要每时每刻都在想着会不会泄露隐私。如果你看完本文后想采取行动保护隐私，以下的网站值得查看（感谢“棱镜门”事件，在此之后不少隐私保护项目如雨后春笋那样冒了出来）：\n逃离棱镜，听名字就知道是专门针对棱镜计划的项目，推荐了各种商业软件/服务的安全替代品，有中文\n隐私工具 - 加密安全对抗全球大规模监控，提供保护隐私的工具推荐，也有中文\nPanopticlick，来测试你的浏览器指纹多么独特（易被跟踪）\n编程随想的博客，信安大牛的中文博客，科普文多，涉及信息安全、保护隐私、匿名术\n摘录   法律因国家而异，科技则不是。每个国家都有自己的法律，但计算机程序码却是相同的。科技跨越边境，持有几乎所有国家的护照。随着时间的流逝，我越来越明白，通过立法改革我出生国的监控机制，未必会对我流亡国的记者或异议人士有所帮助，但加密手机就帮得上忙。\n  只因为我分享我的知识，并不意味着任何人必须认同我的意见。并非每个反对隐私遭侵犯的人，都可能准备好采用 256 位的加密标准，或是全面停止使用网络。\n  从当年的宪法日到现在，已经超过了一个世纪，云端、计算机、手机已经变成了我们的家，如同实际的房子那样隐秘、私人化。如果你不认同这句话，那么请回答我这个问题:你愿意让你的同事一个人待在你家一个小时，还是愿意让他看你已经解锁的手机，就算只是十分钟而已？\n  不过，删除帖文的可能后果让我心烦意乱，那么做只会强化网络生活中的一些最腐蚀人心的训诫：没人有犯错空间，凡是犯错者，都要一辈子为自己的错误负责。我在意的倒不是文字记录是否完美无缺，而是灵魂的完整性。我不想活在一个人人必须假装完美的世界里，那样的世界没有我和朋友的容身之处。抹掉网上的评论，等于抹杀了我是谁，我从哪里来，我走了多远。否定年少时的我，等于否定现在的我的合法性。\n  所谓长大，代表的是你体会到你的存在受制于成套的规范、模棱两可的规则以及毫无根据的常规。这些规定未经过你的同意便强加在你身上，而且随时随地都有可能改变，甚至在你违反规定时，你才意识到它们的存在。\n  美国这个国家已变成买新机器取代故障机器比找专家修理来得便宜，而且一定比自己去找零件设法修理来得便宜。单凭这项事实，便几乎保证会出现科技暴政，助纣为虐的不是科技本身，而是每天使用却不了解机器的所有人。\n  ","date":"2020-02-28T17:11:57Z","image":"https://viflythink.com/Permanent_Record/show_hubd120cde6f5e6b0427e37ac7e424878d_423308_120x120_fill_q75_box_smart1.jpg","permalink":"https://viflythink.com/Permanent_Record/","title":"永恒才是你的敌人——《永久记录》读后感"},{"content":"2020 年已然到来，一些博主已经发表了年度总结，总结了不少经验，我想了想，觉得自己好像没什么可以总结的经验，只好写一篇最近的 KDE 折腾记录给各位读者当新年礼物了。想必有不少刚开始使用 Linux 的新手总想着美化自己的桌面吧，我在开始使用 KDE 后也想着折腾美化，随便搜索了一下美化教程后发现不少都是将 KDE 改造为 Mac 风格的，之前听闻 KDE 粉说过“你可以将 KDE 捏成任何形状”，然而很多人都是将它捏成 Mac 的样子，那么，能把 KDE 捏成 win10 的形状吗？我决定挑战一下这个问题，当然，在这里我要承认这有点标题党的嫌疑，我只是想将我认为 win10 做得好的部分转嫁到 KDE 上，并不是将 KDE 完全变为 win10 的样子，后者是一件费力不讨好的事情，而且，在经过一波折腾后，我发现有些细节还暂时无法做到像 win10 那样优秀，只能寄希望于未来了。另外，本文只适用于 Arch，我尚未在其它发行版进行测试。\n先上一张图片看看改造后的效果（图中标注了下文用到的名词所指代的东西）：\n 我的桌面展示 \n觉得很漂亮吧？那么，接下来就开始我们的改造吧。\n底部栏 在没有打开任何窗口时，底部栏是与 win10 相差最远的一个地方，所以我们的改造工作先从底部栏开始。可以先看看改造完成后的底部栏效果图：\n 底部栏 \n开始菜单 喜欢 win10 那简洁的开始菜单吗，在 KDE 下只需安装一个部件（widgets）即可拥有同样的体验。下载 Tiled Menu，并在底部栏空白处单击右键，然后点击“添加部件”，按照下图所示进行安装。\n 安装部件 \n想要使用的话有两种方法：在你左下角的开始菜单处鼠标右键单击，选择“显示替代方案”，选择 Tiled Menu；在底部栏右键单击，选择“编辑面板”，鼠标移到原来的开始菜单，选择移除，然后选择“添加部件”，选择 Tiled Menu。你可以在弹出的开始菜单右上角按住 ALT 和 鼠标右键进行拖拽以更改菜单大小。\n 将 Tiled Menu 设为开始菜单 \n另外，想实现像在 Windows 那样按下 win 键便弹出开始菜单这一点，还需要做一点设置：右键单击开始菜单并选择“配置Tiled Menu”，点击“Keyboard shortcuts”，然后在下面截图所示位置左键单击并顺序按下 ALT 和 F1 键。\n 设置 Tiled Menu 的快捷键 \n毛玻璃效果 是否觉得在我的截图中的底部栏非常好看呢，这在很大程度上都是毛玻璃效果带来的。想要做到这样的效果，只需安装一个被称为 Breeze AlphaBlack 的 Plasma Themes。下载完成后将其解压到 ~/.local/share/plasma/desktoptheme/，然后打开系统设置，在侧栏点击“Plasma 样式”，选择 Breeze AlphaBlack 并应用更改。重启电脑后就能在系统托盘处见到 AlphaBlack Control（长得像是个雨滴），单击即可进行调整：将“Accent Color”的“Panel, Widget, Window TitleBars \u0026amp; Frames”处的值改为 #343434（默认的纯黑不好看），将“Opacity”的“Panel”处的值调整为 10% 以加强底部栏透明度。\n 设置 AlphaBlack \n另外，你还可以通过以下方法令 QT 系的应用的右键菜单拥有毛玻璃效果：打开系统设置，在侧栏点击“应用程序风格”，选择“应用样式”，找到“微风”，点击右下角的配置按钮，点击“透明度”一栏，将透明度变大。将透明度变大能达到毛玻璃效果的原因是 KDE 默认的半透明是带有模糊效果的，而不是简单的透明，具体的模糊设置可在系统设置下的“工作空间行为”-\u0026gt;“桌面特效”中找到。\n 设置微风的应用程序风格 \n 设置微风的菜单透明度 \n任务管理器部件 依然是在底部栏右键单击，选择“编辑面板”，将鼠标移动到底部栏空白处，点击“显示替代方案”，选择图标任务管理器（Icon-Only Task Manager），然后你就可以看到类似于 win10 的底部窗口了，这里说明一下，图标任务管理器是自带的一个部件，无需安装。\n 设置图标任务管理器 \n快速查看已打开的窗口 win10 可点击左下角的按钮快速查看已打开的窗口，在安装了 Present Windows Button 这个部件后，我们也可以做到这一点。这个部件的安装方法与 Tiled Menu 时相同，在安装完成后把这个部件放在开始菜单和任务管理器之间。这个部件产生的点击效果与在 Gnome 下将鼠标移动到屏幕左上角触发的效果差不多，KDE 也可设置这样的触发角，不过我觉得设置这样的一个按钮没什么实际意义，可能最大的好处就是没事点一下能有效消遣无聊吧（雾）。这里还有一个能让底部栏变得更美观的 Tips，在底部栏右键单击，选择“编辑面板”后点击“添加间距”，以此添加两个间距，将其缩到最小后对其右键取消勾选“设置可变大小”，然后将这两个间距拖到 Present Windows Button 两边，这能令 Present Windows Button 两边不会显得拥挤，从而变得美观。\n其它 想要在其他人面前假装自己在使用 win10 吗，将开始菜单的图标更换为 win10 开始菜单的图标无疑能让 KDE 变得更像 win10。你可以在 IconFinder 上下载 win10 图标，也可使用我在该图标的基础上使用 Inkscape 手动缩小后的 win10 图标。右键单击开始菜单并选择“配置Tiled Menu”即可更换图标。我知道存在 Winux10 之类的图标主题可以将默认的图标替换为 win10 图标，但我经过尝试后发现其覆盖不全面，用以截图假装自己在使用 win10 是可以的，但日常使用会感到违和，所以还是推荐使用默认的图标主题。让我们再关注另一个细节，那就是右下角的时钟，想让它像 win10 那样双栏显示日期和时间并不难：在底部栏空白处右键单击，选择“编辑面板”，左键按住“高度”并进行上下拖拽，这样可以调整面板高度，稍微调高一些后，右键单击时钟，选择“配置数字时钟”，勾选“显示日期”，并将时间显示改为24小时制。\n窗口装饰 KDE 的窗口装饰指的是打开的应用程序窗口的顶部部分（就是包含了最小化、最大化、关闭按钮的那一栏）。我在 Google 搜索如何让 KDE 变得像 win10 时发现了一个非常新的 KDE 主题 Breeze10，从 Github 页面上的图片可以看出这个主题可以完美地将窗口装饰变为 win10 的风格。由于目前（2019年12月）还没人打包，所以需要按照其 Github 页面上的操作步骤进行编译安装。AUR 上已有人打包，所以我们可以在终端输入指令安装（需要安装 Yay 这个 AUR 助手）：\nyay -S breeze10-kde-git  在安装完成后重启系统，打开系统设置，在侧栏点击“应用程序风格”，再点击“窗口装饰”，选择“Breeze10”并应用更改。另外，可以点击那个笔状的图标调整这个主题，例如把字体设置变大。完成后你的应用程序窗口会显得更为美观大方。\n 使用 Breeze10 \n颜色 该怎么说呢，我总觉得开源项目的美工总是不在线：KDE 默认的颜色并不具备所谓的“现代感”。如果你不知道这有多大的影响，可以看看下面使用默认微风与 Canta Light 的 Dolphin 对比：\n 微风 Dolphin \n Canta Light Dolphin \n很明显，Canta Light 主题看上去非常好看，AUR 上已有包，这里依然使用 Yay 安装：\nyay -S canta-kde-git  安装完成后，打开系统设置，在侧栏点击“颜色”，选择刚安装的 Cantalight，应用更改。虽然白色的窗口装饰看着也还不错，但我还是把窗口装饰的颜色改回黑色以配合整体样式：点击上文提到的 AlphaBlack Control 中的“Apply Colors”就能更改颜色。\n其它细节 当你习惯性地用 ALT + TAB 键想要切换窗口时，就会发现在默认设置的情况下窗口列表将在左侧显示，我个人更喜欢 win10 或 Gnome 那样在切换窗口将列表显示在屏幕中间，为了做到这一点，打开系统设置，在侧栏点击“窗口管理”，然后点击“任务切换器”，在“可视化”处选择大图标，可看下图：\n 设置任务切换器 \n我并不喜欢每次点击关机按钮后都要进行确认，而是希望像 win10 那样直接关机，这也是稍微修改系统设置即可做到的事情，打开系统设置，在侧栏点击“开机和关机”，然后点击“桌面会话”，在“常规”处取消勾选“确认注销”。\n差点忘了还有一个细节问题：桌面右上角的按钮好像没什么用，如何隐藏它呢。只需在桌面单击鼠标右键，点击“配置桌面”，再点击侧栏的“调整”，取消勾选“显示桌面工具箱”并点击确定即可。\n总结 经过这么多的折腾后，我总算是大概了解 KDE 了，“你可以将 KDE 捏成任何形状”毕竟只是一句用来吹嘘的话，除非动手改源代码，否则可自定义的部分总是有极限的，例如，在完成上述改造后，我对图标任务管理器并不完全满意，因为其显示的程序图标还是偏大，导致图标之间的间距不足，无法模拟 win10 底部栏的美观大方的感觉，当然，还有其它地方的间距设置也不尽人意，这些都难以通过安装主题等手段进行改造。当然，我个人认为没必要为此下结论说开源项目都处于美工下线的状态，其实无论是 KDE，亦或是 Gnome，它们的整体外观水平已经是与 Windows、Mac 这些商业公司开发的系统持平了，Linux 用户同样能有不差的桌面体验，KDE 等桌面所欠缺的只是一些审美细节，由于我也不懂设计，这里就不多说了。如果有兴趣的话，还可以多翻翻系统设置里的选项，其中包含了大量与桌面相关的自定义选项，这已经提供了非常大的改造空间。最后，在新的一年里，祝各位折腾愉快。\n","date":"2020-01-01T10:08:32Z","image":"https://viflythink.com/KDE_to_Windows10/show_hua1e96627c79bb7cd39936a6d63fa6003_596890_120x120_fill_q75_box_smart1.jpg","permalink":"https://viflythink.com/KDE_to_Windows10/","title":"将 KDE 改造为 Windows 10"},{"content":"前段时间我看到了一篇标题为 Elliptic Curve Cryptography Explained 的既通俗易懂又较为全面的介绍椭圆曲线密码的英语博文，可以说是非常优秀的一篇科普文了。看到目前在中文互联网上介绍非对称加密算法中的 RSA 加密算法的高质量文章有很多，而介绍同样属于非对称加密算法的椭圆曲线密码的高质量文章并不多，所以我将该文章翻译为中文并在我的博客上发表。原文链接是 https://fangpenlin.com/posts/2019/10/07/elliptic-curve-cryptography-explained/ ，已获得原作者授权翻译。由于作者仅要求我注明原文链接，所以这篇译文的文字部分依然按本博客的默认授权协议 CC-BY-NC-SA 4.0 进行授权。对于普通读者而言，这篇文章基本不需要数学知识就可以理解，当然，还是需要了解一些对称加密和非对称加密的基础概念的，为了便于读者理解，我还在一些地方添加了译者注。下面，我们便开始对椭圆曲线密码的介绍吧。\n最近，我正在学习椭圆曲线密码（Elliptic Curve Cryptography）的工作原理（译者注：为了少打点字，下文统一使用 ECC 这一缩写指代椭圆曲线密码）。我在互联网上搜索相关内容，发现了很多解释它的文章和视频。其中大多数仅涵盖了 ECC 中的一部分内容，有一些跳过了许多关于你如何能从这处到达另一处的关键步骤。最后，我找不到真正的能以直观的方式从头到尾解释它的文章。考虑到这一点，我想写一篇解释 ECC 的文章，其内容从基础知识到密钥交换，加密和解密。\n为了绘制本文所需要的曲线，且了解 ECC 的运作方式，我写了两个 Jupyter Notebook 用于使用 Python 进行曲线绘制和计算，用到的绘图库是 matplotlib。另外，如果你想随意操作椭圆曲线，并自己体验一下其运作方式，那你很幸运！我在 GitHub 上开源了源代码，一个适用于实数，还有一个适用于有限域：\n jupyter-notebook \n你可以在 Jupyter Notebook 中找到大多数本文用到的图表。\n请注意，本文并不是为了说明如何安全地实现 ECC，我们在此使用的示例只是为了使你和我自己便于理解或使用（译者注：警告，除非你是专家，否则不要在软件项目中自己实现加密算法，而应当使用现有的成熟的加密算法库）。我们也不想在数学这个兔子洞挖得太深，我只想集中精力了解它的本质的运作方式。因此，我们将剔除许多数学细节，仅提供参考资料供感兴趣的读者阅读。（译者注：本文存在不少星球大战的梗）\n现在，我们开始吧？\n star-trek-into-darkness \n让我们先来玩个游戏 一个椭圆曲线是由 $y^{2} = x^{3} + a x + b$ 定义的曲线。 举个例子，让 a = −3 和 b = 5，然后当你绘制这条曲线时，它看起来像这样：\n elliptic-curve \n现在，让我们玩一个游戏。随机选取曲线上 x 值不相同的两个点，并用一条直线连接这两个点，这两个点我们称为 A 和 B。然后你会注意到直线在除了 A 与 B 外的第三点与曲线接触。让我们找到第三个点并将其 y 值翻转到 x 轴的另一侧（译者注：也就是说以 x 轴为对称轴，将第三个点翻转到另一侧），我们将翻转后的点称为 A + B。\n elliptic-curve-game \n点 A + B 是 A 与 B 的和。你可以认为此过程是某种太空旅行。想象有敌人正紧跟着你的飞船。要摆脱你的敌人，你可以在航线上走直线捷径，到达航线上的另一点，一旦到达第三个点，就会迅速弹跳到路线的另一侧。\n star-war \n好吧，敌人仍然跟着你，让我们再来一次。这次我们从最新的点 A + B 开始，到达另一点 C。\n elliptic-curve-game02 \n如你所见，只要新增的线不是垂直的，我们就可以通过添加新的点来重复相同的技巧，以此跳到一个新的数字。\n随着时间的流逝，你意识到寻找一个新的弹跳落点很麻烦。为了使这个技巧更直观，更容易重复使用，现在让我们沿当前位置 P 的切线走捷径，它看起来像这样：\n elliptic-curve-2p \n考虑前面提到的两点式跳跃技巧，就像你看到点 A 和点 B 在 P 处彼此无限靠近，这实际上是相同的技巧。因此我们可以应用前面的规则，称 P 和 P 的结果之和为 P + P，即 2P。\n同样的，我们可以再一次重复执行相同的步骤以摆脱我们的敌人，这一次，我们从 2P 开始回到起始点 P：\n elliptic-curve-3p \n对于结果，我们将它称为 P + 2P 或 3P。显然，我们可以多次这样做以到达 NP。现在，问题来了，给定点 NP 的坐标，你能找出 N 值吗？换句话说，像下图这样，我们从 P 到 NP 跳了多少次呢？\n elliptic-curve-np \n我可以告诉你，在上图中的 NP 点的 N 值为 13。我很容易说出来，因为我选择了这个数字。但你很难找出答案，因为没有已知的简单而又有效率的方法来计算 N 值。\n就是这样，你已经了解了 ECC 的基础！曲线和起始点 P 是每个人都知道并同意使用的共享值，终点 NP 是你的公钥，分享给任何人都是安全的。你跳了多少步，所对应的值 N 是你的私钥。正如我们上面所说的，只知道 NP 和 P 的人很难推断出你的私钥，因为众所周知这是一个很难解决的问题。\n 没这么快！\n 我听到你这样对我大喊。\n 要到达 NP 点，并不意味着你需要进行 N 次这样的操作。如果你可以在合理的时间内完成该操作，那么我是否可以做同样的事情，即一步一步前进，直到遇到相同的点 NP，这不就确切地发现了需要走多少步了吗？\n 这是一个好问题，实际上我在网上阅读了许多文章后也产生了相同的疑问，但是我发现其中一些文章可以清楚地解释这一点。因此，接下来，我们来讨论在太空中如何真正地使你的敌人无法对你进行跟踪。\n以曲速前进 我们提到了用沿曲线跳跃的技巧以摆脱敌人，然而以缓慢的速度使用这个技巧是不明智的，因为它很容易被追踪。你的敌人可以简单地做同样的事情，直到他们弄清楚到达目的地需要跳跃多少次。为了真正使你无法被追踪，你需要以曲速前进。\n star-trek \n对于求和运算，或者我们在椭圆曲线上使用的技巧存在着一个有趣的特点，这个有趣的特点在于，曲线上的点与其求和运算都遵循群律。其主要想法是，你可以对一个组中的元素进行某些操作，在这里我们称其为“相加”，进行该操作后它们仍将留在这个组中，而且，该操作具有一些特殊的属性。其中被称为关联性（associativity）的一种特殊属性是像这样的：\n(A + B) + C 与 A + (B + C) 是相同的\n这个概念背后的数学证明实际上并不简单，如果你感兴趣，可以在这或这阅读相关资料。虽然很难证明，但是当你画出曲线和直线时很容易看出这一点。让我们来看一个例子。如你所见，我们在上面已得到一个点 (A + B) + C，根据关联性，我们应该能够先执行 B + C，然后再执行 A + (B + C)（译者注：也就是说将 A 与上一步 B + C 的结果相加），并且执行这两步后应该到达相同的终点。下图是 B + C：\n elliptic-curve-bc-first \n接下来，让我们执行 A +（B + C）：\n elliptic-curve-a-plus-bc \n看下终点，它与（A + B）+ C 完全相同。不相信我吗？这是我编写的程序中输出的值：\nab_c = ab + c a_bc = a + bc (ab_c, a_bc) (Point(0.9531851331698311, 1.733918191357413), Point(0.9531851331698316, 1.7339181913574133)) 如你所见，ab_c 与 a_bc 几乎是相同的。其中的差异是由浮点运算的舍入误差造成的。这实际上是一个大问题，我们将在后面讨论这一点。\n类似地，对于单点情况，群律允许我们以不同的顺序进行求和以到达相同的位置。这一点很关键，还记得我们如何通过 P + 2P 到达 3P 吗？现在我想告诉你 P + 3P = 4P 与 2P + 2P = 4P 是相同的。\n首先，让我们看一下愚蠢的计算方式，即只是继续将 P 与 3P 相加。这是计算 P + 3P 的最后一步：\n elliptic-curve-p-plus-3p \n然后，让我们尝试将 2P 与自身相加，这恰好是我们之前使用的技巧：\n elliptic-curve-2p-plus-2p \n看到没有？两种方式都产生了相同的结果。就这样，我们可以轻松地将一个点加倍(double)，并且进行相加操作的顺序无关紧要。我们可以通过不断对一个点进行加倍操作来“作弊”，从而快速生成我们想要的值，不再需要将其一一加起来。\n让我们尝试通过求和到达一个更大的数字，例如 227P，我们首先将其转化为二进制数字，以便获得其两个成分的幂。其二进制表示为 11100011。换句话说，将两个值的所有幂加起来就是： $$2^{7}P + 2^{6}P + 2^{5}P + 2^{1}P + 2^{0}P$$ 也就是：128P + 64P + 32P + 2P + P。\n所以我们需要的操作步骤是（译者注：原作者在这里说的很简单，为了让译文更易懂，这里参考 https://zhuanlan.zhihu.com/p/36326221 添加了一点对操作步骤的补充）：\n 将 P 与 0 相加，同时 P 加倍得到 2P 将 2P 与 P 相加得到 3P，同时 2P 加倍得到 4P 由于在二进制表示中从右到左的第三位为 0，所以不将 4P 与 3P 相加（以此类推，下面不再说明不相加的原因），只是 4P 加倍得到 8P 不将 8P 与 3P 相加，只是 8P 加倍得到 16P 不将 16P 与 3P 相加，只是 16P 加倍得到 32P 将 32P 与 3P 相加得到 35P，同时 32P 加倍得到 64P 将 64P 与 35P 相加得到 99P，同时 64P 加倍得到 128P 将 128P 与 99P 相加得到 227P，同时 128P 加倍得到 256P  这仅需 8 步，与 227 步相比，这种方法快得多了。此方法被称为 double and add。它使我们可以快速地在一个椭圆曲线上跳跃以到达所需的点。在此示例中的数字 227 是很小的，我们可以在 $O(\\log{}n)$ 的时间复杂度下到达我们期望的数字，就算这个数字是与宇宙中原子的数量一样大（一般而言是 $10^{82}$，约等于 $2^{275}$），此方法仍可以在 275 次 double and add 操作后完成计算。\n现在我们知道了如何以曲速在椭圆曲线上向前跳跃，因此，我们可以轻松地向前跳跃数十亿次。虽然这个操作对我们来说很容易，但是对于攻击者而言，要准确地找出我们跳了多少次是极其困难的，此问题等价于：在给定 NP 与 P 且 N 足够大的情况下，找出 N 值。这被称为椭圆曲线离散对数问题，如果你想了解有关此主题的更多信息，可以自己去网上搜索。\n让我们在一个秘密的地方会面 我们之前一直在谈论如何以光速在愚蠢的椭圆曲线上跳跃，但是加密呢？别急，我们这就介绍它。在此之前，让我们首先谈下密钥交换。\n想想看，Alice 和 Bob 正在太空旅行，他们将交换反抗军新总部的位置。突然，他们发现帝国的无人机正在尾随他们并拦截他们飞船之间的通信。为了安全地交换信息，他们同意在只有他们两个都知道的秘密坐标下会面。但是，如果敌人正在窃听，他们如何交换这个秘密坐标呢？现在，ECC 在这里为他们提供帮助。下面是 Alice 和 Bob 要做的事情：\nAlice：\n 嘿，Bob，让我们将 P 作为起始点，这是我的公钥 NP。\n Bob：\n 以 P 为起始点对我来说听起来不错，而我的公钥是 MP。\n 在这里，按照我们之前的定义，NP 是 P 经过 N 次相加运算后得到的点。同样的，MP 就是 P 经过 M 次相加运算后得到的点。\n接下来，Alice 得到 Bob 的 MP 值，对 MP 自加 N 次：\n$$\\underbrace{MP + MP + \u0026hellip; + MP}_\\text{N times} = N \\times MP$$\n对于 Bob，那就变成了取得 Alice 的公钥 NP 后将此点自加 M 次：\n$$\\underbrace{NP + NP + \u0026hellip; + NP}_\\text{M times} = M \\times NP$$\n嗯，M 和 N 都很大，因为我们不希望敌人轻易地找到它。显然，上面的自加操作并不是真的一一相加，而是通过使用我们刚刚介绍的 double and add 技巧来作弊。最终，他们将会在一个只有他们知道的秘密坐标 SK 上会面：\nSK = (N × M)P = (M × N)P\n想想看，对于 Alice，每次跳跃的值是 P 点的 M 倍，而她跳跃了 N 次。对于 Bob 而言，每次跳跃的值是 P 点的 N 倍，而他跳跃了 M 倍。假设 Alice 一次跳跃 4 光年，而她总共跳跃了 3 次；Bob 一次跳跃 3 光年，他跳跃了 4 次。对应的运算分别是 4 × 3 与 3 × 4，它们都将在 12 这里结束：\n ecdh-jump \n对于窃听者，他们需要找出 N 或 M 才能获得相同的坐标。通过一步一步运算，最终也会到达终点。但是，正如我们前面提到的，鉴于数字足够大，以致没有简单的方法可以做到这一点，因此我们可以确定只有 Alice 和 Bob 才能知道这个秘密坐标。这种密钥交换协议被称为椭圆曲线 Diffie–Hellman 密钥交换。\n加密 现在让我们谈谈加密。Alice 想要安全地向 Bob 发送信息，他们需要首先进行我们上面刚刚提到的椭圆曲线 Diffie–Hellman 密钥交换：\n ecdh-encryption-key-exchange \n这里请注意，Alice 需要能够验证公钥 MP 真的是属于 Bob 的。否则，冒名顶替者可以向 Alice 提供自己的公钥，并声称自己是 Bob，然后，Alice 将与攻击者交换共享密钥，再然后，攻击者就可以执行中间人攻击。 要解决该问题，就需要另一个概念，它被称为公钥基础架构，因为这个属于离题范围，如果你感兴趣，可以搜索相关资料。\n由于今天我们只想专注于 ECC，所以在此假设 Alice 已经取得 MP 并不加思索地相信它来自 Bob，而 Bob 也得到了 Alice 的公钥。现在，在交换密钥之后，他们最终得到了相同的共享秘密坐标，我们可以得到 x 值作为密钥。一旦我们拥有一个共享的密钥，一切就很简单了。得到共享密钥后，我们可以在任何安全的对称加密算法中使用共享密钥 SK 对我们的机密数据进行加密（译者注：出于性能因素的考量，通常只使用 ECC 等非对称加密算法交换对称加密算法所需的共享密钥，此后的通信使用对称加密而不是非对称加密算法进行加密，在这里就是这样做的）。假设我们在这里使用 AES256。接收者 Bob 可以使用相同的共享密钥 SK 解密经过加密的消息。\n ecdh-encryption-encrypt \n太好了，现在即使帝国的无人机窃听了所有通信，Alice 仍可以安全地将反抗军的新总部位置分享给 Bob。同样的，Bob 可以使用相同的共享密钥 SK 加密消息，并将其发送回 Alice。\n当 Alice 和 Bob 彼此认识时，我们知道可以使用 ECC 安全地发送消息。但是，如果在某些情况下我们想安全地向某人发送消息，但他们不知道并且可能不在乎你是谁，该怎么办？简单，我们在这举个例子，假设 Bob 已经知道 Alice 的公钥，如果 Alice 知道 Bob 的公钥 MP，她可以使用她自己的私钥 N 生成相同的共享密钥 SK，加密数据并将纯文本形式的公钥 NP 与经过加密的数据一起发送出去。一旦 Bob 收到消息，他就可以使用 NP 和他的私钥 M 创建相同的密钥 SK 并解密经过加密的数据。但是，由于信息中附带的公钥 NP 可能属于任何人，因此 Bob 将无法确认消息是来自谁的。如果 Bob 不在乎发送者是谁，Alice 也可选择为同一操作创建一个临时的新密钥对。\n浮点数的问题 到目前为止，我们一直在讨论在实数范围进行计算的 ECC。我们在这里使用实数的原因是，它更易于解释和理解。在现实世界中，这实际上并不是我们进行加密的方式。使用实数会带来很多问题，我们之前展示的一个大问题就是会出现计算错误。还有另一个问题，在某些极端情况下，该数字可能会非常大，而浮点数可能无法容纳它。\n要回答你可能会问的这个问题，我们给出的答案是在有限域，或者更精确地来说是在对整数 p 取模（p 为质数）的有限域上进行计算。同样的，我们也不想将兔子洞挖得太深，因此，如果你对此有兴趣，可以阅读 Elliptic Curve Cryptography: finite fields and discrete logarithms，或者观看 Trustica 的系列视频及其相关文章。\n要解释数学中的位于对整数 p 取模的有限域的椭圆曲线：\n$$y^{2} \\equiv x^{3} + a x + b\\pmod{p}$$\n先让我们取 p = 19，a = −3，b = 5，然后画出来：\n elliptic-curve-on-finite-field \n这看起来似乎不太像是一条“曲线”，但这确实是在有限域上的椭圆曲线。基本上，$y^{2}\\pmod{p}$ 仅在特定整数点上等于 $x^{3} + a x + b\\pmod{p}$。以点(11,7)为例，对于 y：\n$$y^{2} \\equiv 7^{2} \\equiv 49 \\equiv 11 \\pmod{19}$$\n以及对于 x：\n$$x^{3} + a x + b \\equiv 11^{3} - 3 \\times 11 + 5 \\equiv 1303 \\equiv 11 \\pmod{19}$$\n由于两者在被 19 相除后得到相同的余数 11，所以这确实是曲线上的一个点。\n虽然它看起来不像是一条曲线，但它确实与在实数范围的椭圆曲线一样遵循相同的群律。让我们看一个例子，假设点 A = (3,2)，B = (5,18)，并使用相同的相加操作来计算 A + B：\n elliptic-curve-on-field-a-plus-b \n是的，在有限域上的该曲线有些特殊，当一条线到达边界时，实际上可以弯曲到另一端，因为取模操作就是在绕来绕去的。这条线会碰到第三点，就像是在实数上的曲线一样。\n在此给出我们的例子，(18,8)是我们要到达的点。然后将 y 值 8 翻转为 −8 并将其除以 19 取余，这将会得到(18,11)。 因此，A 和 B 的和为(18,11)。\n为了让这更容易被理解，我个人非常喜欢将其以甜甜圈的形状呈现在 3D 空间中，就像 Trustica 的关于 ECC 的视频系列那样：\n elliptic-curve-on-field-donut \n但是考虑到我正在写一篇文章，所以在此将其以简单的 2D 图像呈现出来更加容易。\n现在，让我们向 A + B 点添加一个新点 C = (10,14)：\n elliptic-curve-on-field-ab-plus-c \n接下来，让我们看看群律的关联性是否仍适用于有限域，这一次我们首先添加 B + C 点：\n elliptic-curve-on-field-b-plus-c \n然后，我们将 A 加到 B + C 点：\n elliptic-curve-on-field-a-plus-bc \n是的，它们最终都在同一个点(14,16)：\na_b = a + b b_c = b + c (a_b + c), (a + b_c) (Point(p=19, x=14, y=16), Point(p=19, x=14, y=16)) 现在你可能会问，在有限域上如何对一个点进行自加操作？是的，对一个点进行自加操作也是遵循与实数域相同的规则，即用有限域上的切线连接第三点。正如我们已经展示的它如何处理实数一样，我们不想在这里重复一遍，或者说实际上是因为我很懒😅。\n最后，由于有限域仅在整数上进行运算，所以我们不会损失任何精度。这令它更适合用于密码学。\n","date":"2019-12-14T00:00:00Z","image":"https://viflythink.com/translate_elliptic_curve_cryptography_explained/show_hu5601238948948f72ac070df8361310aa_232702_120x120_fill_q75_box_smart1.jpg","permalink":"https://viflythink.com/translate_elliptic_curve_cryptography_explained/","title":"【译】椭圆曲线密码介绍"},{"content":"在用了将近两年的 Debian 后，我打算尝试另一个与 Debian 存在较大差别的发行版，做了一番比较后（并没有）选择了相比 Debian 激进许多（经常需要滚包）的 Arch Linux。其实我在刚开始使用 Debian 时便听说过 Arch Linux 了，这都要归功于活跃的Arch Linux 中文社区，里面的人整天忙着安利 Arch Linux（传教），而且，Arch Linux 的 Wiki 也是非常优秀的文档，我在 Debian 上遇到问题时也会参考 Arch Linux 的 Wiki，久而久之，便产生了尝试 Arch Linux 的想法，此外，对于现在的我而言，Arch Linux 的哲学也非常有意思，其中提到：\n Arch 适用于乐于自己动手的用户，他们愿意花时间阅读文档，解决自己的问题。\n 这完全符合我想折腾 Linux 的想法！当然，我认为 Arch Linux 并不适合 Linux 新手，因为光是第一步的命令行安装系统（Arch Linux 官方没有提供图形化安装界面）恐怕就能劝退不少人了，不过对于接触过 Linux 的人，通过理解 Arch Linux 安装过程中所需要输入的指令的含义，能体会到一种完全掌握自己的系统的快感（误入邪教）。总而言之，对于喜欢折腾的人来说，尝试 Arch Linux 是绝对不会后悔的决定。\n由于 Arch Linux 的激进策略，安装教程很容易过时，我也不打算费力不讨好地写具体的安装步骤了，本文主要分享我在 Arch Linux 下使用的软件，希望能安利更多人使用（提到的不少软件都是跨平台的，即使不使用 Arch Linux 也可使用这些软件）。先在这里说一下我挑选软件的原则：通用性是最重要的，无论在哪个平台上使用都具有近乎一致的体验，为此没有利用单个平台的特性也是可接受的；数据可无障碍导出与导入，尊重用户的选择自由；简单易用且具备可扩展性（例如可安装扩展增强功能），但我也不排斥“一次配置，终身受用”这样需要折腾的软件；当然，开源是最好的。能达到这些要求的软件实属少数派，我在下文仅仅推荐几个，有空再补充。\n安装 考虑到 Arch Linux 经常变动，所以最好的安装指南应该是官方的Installation Guide，我另外也参考了两篇博文，一个是萌狼的给 GNU/Linux 萌新的 Arch Linux 安装指南 rev.B，另一个是以官方Wiki的方式安装ArchLinux（由于 2019 年 10 月 Arch Linux 将 base 包组替换为同名的元包，这篇教程已过时）。对于我这样存在多系统的情况，执行了 grub-mkconfig 后最好检查一下/boot/grub/grub.cfg 是否包括了所有的系统。 有关于桌面环境的选择，鉴于之前总是看到各位大佬吹 Arch Linux 的 KDE 桌面的美观，而我一直在 Debian 下使用 Gnome，这回便决定尝试 KDE（其实是为了在出问题时更容易找到大佬求救），在安装了 kde-applications 后，开始嫌弃如此多的用不上的应用了（说的就是教育与游戏分类下的那堆东西），所以花了点时间写了一个简单的 Python 脚本删除这些软件（需要 root 权限，使用需谨慎）。安装完成后重启进入桌面，我不得不表示默认的 KDE 桌面比 Gnome 漂亮多了，相比之下，Gnome 的塑料风格看着实在是让我难受。另外，KDE 全家桶之间的配合也令我十分满意，统一的设计风格，美观的特效，让我忍不住想吹爆 KDE 了。有一个值得一提的细节，在 KDE 下的鼠标单击等于其它桌面环境下的鼠标双击（例如在其它桌面环境下打开文件需要双击），一开始我并不习惯这种设置，觉得不便于选中单个文件，但用多了以后发现这种操作明显更轻松，因为平常使用鼠标时双击的频率比单击要高，而双击肯定比单击累，将双击替换为单击肯定可以减缓疲劳，对于需要选中单个文件的情况，右键也能满足需求，这又成了一个我喜欢 KDE 的原因。\n除了桌面环境外，首先需要熟悉的还有 Arch Linux 的软件包管理器 Pacman，它的命令行参数与 apt 完全不一样，开始使用时经常需要查看其Wiki 页面，值得一提的是，得益于AUR(Arch User Repository) 的存在以及 Arch Linux 打包的低门槛，Arch Linux 拥有数量庞大的软件包，考虑到可能会使用 AUR 里的软件包，所以我安装了Yay 这个AUR 助手（Yay 完全兼容 Pacman 的命令行参数）帮我节省输入 makepkg 等指令的步骤，下文涉及到安装软件的指令既有可能使用 Pacman，也有可能使用 Yay。\n中国大陆用户所需的东西 中文设置 我直接根据Linux 下的字体调校指南一文进行调教，在这里我想说一下该博文中提到的“archlinuxcn required”，这意味着需要添加 archlinuxcn 源，上面介绍已经提到了 Arch Linux 中文社区，而这个社区维护着一个非官方软件仓库，被称为 Arch Linux 中文社区仓库（archlinuxcn 源），该仓库包括了很多中文用户会用到的已编译好的软件包，而 AUR 提供的是 PKGBUILD 打包脚本（这就是为什么你可通过 AUR 安装不少明确禁止二次分发的闭源软件的原因，因为 AUR 分发的是打包脚本而不是软件本体），需要下载后进行编译打包安装，如果你懒得自己打包的话，建议添加 archlinuxcn 源。在配置完成中文字体的显示后，在 KDE 的系统设置中将语言设置为中文就行了。另外，强烈建议阅读官方的Arch Linux 中文化页面。\n翻墙 折腾 Linux 总是会遇到各种问题，这种时候便需要 Google 了，让我们先解决使用无法使用 Google 的问题（此处使用 V2Ray 作为例子，在官方软件仓库有 V2Ray 的软件包真是太好了）：\nyay -S v2ray  安装后修改/etc/v2ray/config.json 的配置，然后：\nsudo systemctl enable v2ray.service sudo systemctl start v2ray.service  如果想让桌面应用走代理，可以在 KDE 的系统设置中点击“网络”中的设置，然后点击“代理”，选中“使用系统代理服务器配置”，填入对应的代理信息，示例如下：\n KDE 设置系统代理 \n另外，V2Ray 支持 ShadowSocks 协议，可根据V2Ray 官方文档写出配置文件，也可使用在线工具生成；如果你使用 SSR 翻墙，AUR 中有electron-ssr，也有shadowsocksr，但需要注意的是 electron-ssr 无法在 KDE 下自动设置代理（它使用了 gsetting 设置系统代理，不支持 KDE）。总之，安装好翻墙软件后终于能在电脑上使用 Google 查问题了。\n终端模拟器与 Shell 既然在 Linux 下，那么肯定免不了与终端打交道，既然如此，我们就需要一个美观、实用的终端（模拟器）。要说美观的话，KDE 自带的 Konsole 已经足够漂亮了，透明背景这一点让一直使用 Gnome Terminal 的我感到非常舒服，只需要稍微调整一下，就可以做到kiri 大佬这样的效果，让自己一整天都保持心情愉悦。不过在实用性方面我开始时遇到了一点问题，Konsole 使用的 Shell 是 Bash，而 Arch Linux 本身的 Bash 并没有自动补全配置，想要自动补全的话需要安装 bash-completion：\nsudo pacman -S bash-completion  想要更高级的 Shell 体验的话（不知道终端模拟器与 Shell 有什么区别？请看这），也可以安装 zsh 加 oh-my-zsh 这样一整套的懒人包（或者自己配置 zsh？），只不过这里有一个小坑，在 AUR 中的 oh-my-zsh-git 并不会在 home 目录下生成 .zshrc，查找后发现在 /usr/share/oh-my-zsh 下有 zshrc 文件，我直接复制到 home 目录了，这里贴出安装懒人包的操作命令（将 username 改为你的用户名）：\nyay -S zsh sudo chsh -s /bin/zsh username yay -S oh-my-zsh-git cp /usr/share/oh-my-zsh/zshrc ~/.zshrc  更新：博主已经放弃启动速度慢的 oh-my-zsh，转向 Zinit 这个神器的怀抱了，另外，2021 年 11 月 Zinit 的原作者删除代码库，目前由 zdharma-continuum 组织接手进行维护，请注意 URL 的变化。Zinit 不仅轻松可以使用 oh-my-zsh 的各种插件，还拥有 Turbo mode 这个大幅减少插件加载时间的大杀器。如果你心动的话，请看加速你的 zsh —— 最强 zsh 插件管理器 zplugin/zinit 教程一文。仅仅是照抄文末的示例配置，我也在保留 oh-my-zsh 体验的前提下感受到了起飞的加载速度，所以请无视上面的 oh-my-zsh，使用以下指令体验顺滑如丝的 Zinit（这里用了配置难度低的 proxychains-ng 翻墙下载 GitHub 片段，也可使用其它手段）：\nyay -S zsh proxychains-ng git clone https://github.com/zdharma-continuum/zinit.git ~/.zinit/bin # 在 .zshrc 中添加 source ~/.zinit/bin/zinit.zsh 以及其它配置，可参考我的配置 nano .zshrc # 配置 proxychains-ng，在最后一行添加类似 socks5 127.0.0.1 1080 的内容即可，自行谷歌了解配置 sudo nano /etc/proxychains.conf # 启动 zsh，由于 .zshrc 已加载 Zinit，所以 zsh 首次启动时会自行下载 GitHub 上的片段 proxychains zsh # 下载片段完成后退出执行这条指令更改默认 Shell，重启后见效果 sudo chsh -s /bin/zsh username  你可以在GitHub 查看我的 zsh 配置，不过请记得根据自己的需求进行修改。\n输入法 前面搞定了中文字体的显示，但是还没解决输入中文这个问题，在这里我选择了与使用 Debian 时同样的方案：基于 Fcitx 框架的 Rime 输入法。先贴一波安装指令（其它基于 Fcitx 框架的输入法请看Wiki 页面）：\nsudo pacman -S fcitx fcitx-im fcitx-rime  为了确保能输入中文，修改一下/etc/profile，在开头加上：\nexport XMODIFIERS=\u0026quot;@im=fcitx\u0026quot; export GTK_IM_MODULE=\u0026quot;fcitx\u0026quot; export QT_IM_MODULE=\u0026quot;fcitx\u0026quot;  另外，需要更改一下输入法配置，操作步骤是右键点击托盘中的输入法图标，选择“配置”，修改后的配置如下图所示（按 Shift 键可切换中英文）：\n 输入法配置图1 \n 输入法配置图2 \n最后，将我已经在 Debian 上调校好的 Rime 输入法配置文件拷贝过来（调校 Rime 的教程太多了，这里懒得贴了～），就能畅快地输入中文了。\n多媒体 这里选择在 Debian 上非常熟悉的 MPV 和 Rhythmbox 作为视频和音频播放器，之所以选择 MPV 是因为我已经有了一套配置方案，没必要选择其它播放器了，如果你还没使用过 MPV，那么这里有一篇相当不错的配置教程。而 Rhythmbox 支持不少插件，例如，在 KDE 桌面下，Rhythmbox 无法在关闭窗口时隐藏到托盘继续播放，可以通过安装 rhythmbox-tray-icon 插件解决：\nyay -S rhythmbox-tray-icon  安装好插件后记得点击 Rhythmbox 右上角的设置按钮-\u0026gt;“插件”，在弹出的窗口中勾选刚安装的插件以激活插件效果，如下图：\n Rhythmbox 插件 \n除此以外，我还推荐 rhythmbox-equalizer 插件，安装后可调整 EQ。\n生产力 属于生产力的工具有很多，我在这里只选择分享几个比较重要的工具。如果平常使用的生产力工具没有 Linux 客户端，或许可用网页版代替客户端（连网页版都没有的话，折腾下 wine 或放弃在 Linux 下使用吧）。\n浏览器 都说程序猿是面向 Google 编程的，既然如此，怎能缺少一个趁手的浏览器用于查资料呢。直接安装我在 Debian 上一直在使用的 Firefox 与 Chromium（Google Chrome 的开源部分）：\nyay -S firefox-i18n-zh-cn chromium  这两个浏览器都有云同步机制，可直接将在其它平台上的浏览器资料同步过来，不想使用云同步的话，也可以手动复制用户资料以进行数据备份和迁移，Chromium 的用户资料在~/.config/chromium/Default/，浏览器扩展及其数据存放在这个目录下带有“Extensions”的子目录中；Firefox 有些不同，它轻松支持多个用户配置，你可以打开about:profiles 页面查看用户配置文件路径，显示“正在使用此配置文件，因而不能删除。”的就是当前的用户配置文件。 对于我来说，选择这两个浏览器的一个重要原因就是可以安装扩展改善各种功能，例如禁用 JS 的 NoScript/ScriptSafe，拦截广告的 uBlock，为网页注入实用 JS 的 Greasemonkey，对于 Firefox 用户，还可参考编程随想的无需任何插件或扩展，定制 Firefox 外观和扫盲 Firefox 定制——从“user.js”到“omni.ja”进行更高级的定制。另外，从安全补丁的及时性这一角度来说，我也更推荐这两个浏览器，而不是基于这两者的衍生版。\n代码编辑器与IDE 要问对程序猿而言最重要的生产力工具是什么，回答肯定是代码编辑器或 IDE。目前在 Linux 下我喜欢的编辑器就是 Visual Studio Code（简称 VS Code）了，虽然这是微软出品的（别跟 VS 搞混了，两者之间的差别非常大），不过用了以后还是要说一句“真香！”。它可以胜任多种需求，常见的 Python、C/C++等完全不在话下，也可以用作 Markdown 写作，像本文就是在 VS Code 下完成的，当然，值得一提的还有美观的界面，开箱即用的设置，这都令它在短时间内打动了我，再配合各种扩展，带来的是十分舒适的体验。对于 VS Code，我目前推荐 TabNine 以及 Markdown Preview Enhanced 这两个扩展，前者带来优秀的主流编程语言自动补全，后者带来更高级的 Markdown 预览体验（例如查看 LaTex）。\n VS Code 图 \n如果需要一个 IDE 的话，我推荐由 JetBrains 出品的 IDE，应该有不少人用过它家的 PyCharm 了，除此以外，Clion(C/C++)与 IntelliJ IDEA(Java)也是非常优秀的 IDE，至少在目前来说，Clion 对 Cmake 项目的支持可比 VS 好多了。另外，配合 Github 的学生认证可以白嫖 JetBrains 的产品，在此强烈推荐学生党尝试一下 Clion。\n笔记 作为一个程序猿，总是会有记录笔记的需求，我目前有相当一部分的笔记资料储存在 EverNote 这个云笔记上，而它并没有 Linux 官方客户端，不过，得益于它的开放 API，早就有开发者做了一个在 Linux 下的客户端：NixNote（原名 Nevernote），Arch Linux 官方仓库有这个软件包：\nsudo pacman -S nixnote2  只不过我遇到了在已设置应用程序使用语言为中文的情况下，菜单依然为英文的问题，Google 后找到一篇让 NixNote 显示日语的教程，受到这篇教程的启发，我查看了一下/usr/share/nixnote2/translations/目录，发现其中只有 nixnote2_cs_CZ.qm 文件，看来想要让菜单显示中文，就必须在这个目录下添加中文翻译。具体来说，先前往 GitHub 仓库下载中文翻译源文件，接着使用 Qt Linguist 打开下载回来的文件，然后点击左上角“File”-\u0026gt;\u0026ldquo;Release As\u0026quot;导出到/usr/share/nixnote2/translations/nixnote2_zh_CN.qm。重启 NixNote 便可以看到中文菜单了。更新：2020年5月的更新已带上中文翻译，无需再按上面折腾。 当然，EverNote 在 Linux 下还有几个非官方客户端，我选择 NixNote 的原因在于它是使用 C++ QT 开发的，而不是类似于Tusk 等使用前端技术开发的套壳 Web 应用，但对于 EverNote 的高级用户，我建议使用 EverNote 的网页版，而不是使用 NixNote，因为网页版的编辑功能比 NixNote 更优秀。\n虚拟机 我有时候会有使用虚拟机运行 Windows 或其它 Linux 发行版的需求，这个时候就需要用到虚拟机了，VirtualBox 是一个操作简单且免费开源的虚拟机软件，根据Wiki 页面进行安装（安装时会要求选择内核模块，没有更换默认内核的话，选择 virtualbox-host-modules-arch，不然选择 virtualbox-host-dkms）：\nyay -S virtualbox virtualbox-ext-oracle virtualbox-guest-iso  假如你没有用过 VirtualBox，那么这里提醒一句，拖放文件和共享粘贴板等功能需要在运行中的虚拟机窗口上方点击“设备”-\u0026gt;“安装增强功能”才可使用。\n后记 得益于我对软件的通用性的要求，可以说是无痛从 Debian 迁移到了 Arch Linux，不少软件只需简单地复制粘贴配置文件即可（前提是已经有配置文件了），而且 Arch Linux 的系统安装过程也并不像我之前想象的那样复杂。折腾完这堆东西后最大的感触就是之前折腾积累的东西（如相关知识与配置）并没有浪费，若是没有相关的积累，面对安装 Arch Linux 以及安装完成后做什么这些问题恐怕会一头雾水，浪费不少时间，从节约时间的角度来说，编程随想所说的重视个人 IT 基础设施的改善是很有道理的。总之，安装好 Arch Linux 的我就像是一个刚得到新玩具的小孩子，正迫不及待地想要探索这个新玩具的有趣之处，更多有趣的软件留待日后补充好了。\n","date":"2019-11-03T14:34:27Z","image":"https://viflythink.com/Try_Arch_Linux/show_hubfb0eb0e288deb4ca723092859008c14_673819_120x120_fill_q75_box_smart1.jpg","permalink":"https://viflythink.com/Try_Arch_Linux/","title":"从 Debian 迁移到 Arch Linux"},{"content":"前几天突然有了一个很有趣的想法，假如能与一年前刚入门深度学习的我进行交流，那么此时的我会有什么经验想分享给过去的我呢？想到入门深度学习以来踩的各种坑以及经历过的迷茫，我决定写一篇文章，从过来人（入门一年？）的角度说一下对新手的一些建议。由于我的水平有限，所以文章肯定会有遗漏与错误之处，望各位大佬轻拍。\n常见问题解答（FAQ）   问：网上好多深度学习入门教程啊，该选择哪个呢？\n答：随便在 Google 上搜一下“深度学习入门”，就能找到不少高质量的回答以及学习资源分享。我并不想在这推荐什么学习资源，因为在这方面的好文章太多了，我只想强调一点：无论你选择了哪个入门教程（书籍），都请专注于该教程，不要总是被五花八门的教程扰乱自己，任何教程都是殊途同归的，学成后的效果总是一致的。其实最关键的是需要有一个明确的目标，我会在正文突出学习目标，当你在学习时只需关注如何达成学习目标即可。\n  问：我的数学/英语水平低，会不会难以入门？\n答：其实不必那么担心。在我看来，入门深度学习对数学并没有太高的要求，入门阶段只需要知道导数与积分，矩阵等几个概念即可；至于英语，我只能说即使是天天翻阅英语文档的程序员也不见得能熟练地使用英语，想学习深度学习，能记住英语术语即可。如果一定要说入门有什么要求的话，我觉得能使用 Google 查找资料和不畏惧英语阅读这两点是必需的，当然，还需要一点编程能力。\n  问：学习深度学习需要懂编程吗？\n答：实战部分需要（可能有些教程在讲解理论时也会贴一段 Python 代码），但是要求不高。目前（2019 年）学术界的主流编程语言依然是 Python，假如你有编程基础，那么只需花 3 天时间学习 Python 基础语法即可，深度学习并不需要 Python 的高级语法知识；如果没有编程基础，请先老老实实地找个 Python 入门教程学习，不必担心难以学习，Python 作为一门小学生都能学会的编程语言，相信你用半个月到一个月的时间足以学会它的基础语法。\n  理论 首先，回答一个问题：你是为了什么而决定学习深度学习呢？是需要与老师做深度学习相关的科研项目？开发软件项目时需要用到深度学习？还是觉得近几年深度学习很火，想学习一下？如果只是软件项目中需要深度学习，那么可以考虑直接使用腾讯等大厂提供的 API，这些 API 可以实现图片分类等许多实用的功能。对于我来说，我是在跟着老师做计算机视觉（CV）科研项目时开始学习深度学习的，此前并没有相关经验。在这种情况下如何学习一个新的技术呢？完全可以根据学习技术的三部曲：WHAT、HOW、WHY中提到的 WHAT、HOW、WHY 这三个步骤进行学习，不过要注意的一点是在深度学习中想达到 WHY 这一步非常困难（学到后面就会发现神经网络基本是一个黑盒，所以训练模型也被戏称为炼丹）。先说下如何知道 WHAT 吧，想要知道 WHAT，你就必须知道深度学习中常见的名词的含义，例如卷积、梯度下降、神经网络、前向传播、反向传播等，最重要的是，知道神经网络的训练流程是怎样的。这一步比较简单，我推荐观看吴恩达的Deep Learning Specialization系列视频，上面有 5 门课程，每门课程都安排了 4 周的学习时间，但实际上我们不必全部看完，只需观看课程 1、2 即可，凡是需要写代码的练习全部跳过，因为我们只需要了解概念，等下我会说明如何进行实战练习。跳过课程 3 是因为入门阶段可以无视机器学习。准备进入计算机视觉（CV）领域的请另外看课程 4 的第一周的视频，了解卷积神经网络（CNN）的概念；准备进入自然语言处理（NLP）领域的请另外观看课程 5 的第一周的视频，了解循环神经网络（RNN）的概念。（PS：因为好奇而学习深度学习，不知道 CV 和 NLP 是干什么的？先去查下这两个领域有什么应用吧，看看哪些是你感兴趣的或者未来工作可能会用到的）\n除了吴恩达的深度学习系列视频，你也可以通过看书完成这一步，只不过我没有仔细看过深度学习入门的书籍，所以不做推荐。无论如何，在这一个阶段，你必须对深度学习有整体的认识。检验是否达成这一目标的方法是回答一个问题：深度学习中的训练是怎么一回事？尝试用尽可能少的专业术语进行简短的描述，思考出答案后与我的回答进行对比看看。\n对于上面的问题，我的回答就是构建一个神经网络，不断输入数据与标签，其根据数据与标签之间的对应关系调整自己的参数以令输出与标签一致（只限于监督学习）。说到这里，你可能会问：“诶？那么反向传播的实现这类问题呢？”。这已经是属于 HOW 这一范畴的问题了，你如果能清楚知道这类问题的答案那当然是一件非常好的事情，不过只记得大概的描述也没关系，知道 WHAT 以后，我们就已经可以使用深度学习框架进行实战了，只不过若是想要继续发展，请一定要花时间了解神经网络的实现细节，程序员可以不了解使用的技术的细节，但搞科研的必须了解细节。说了这么多关于了解概念的经验，接下来该说下肯定有不少人关注的实战部分了，对于 IT 行业的人来说，这部分会比较轻松。\n实战 首先，我们先来聊点与编程有关的东西。想要进行实战，那么必须懂得 Python 基础语法，只是用 Python 如何实现在理论教程中吹了那么久的神经网络呢？先选择一个深度学习框架吧，我推荐选择 Keras 或者 Pytorch，这两个在目前是主流，而且简单易用（都 9102 年了，Tensorflow 该让位给 Keras 了）。为什么我推荐先学习使用深度学习框架而不是按照一些教程所说的先使用 Numpy 等库实现一个简单神经网络的训练呢？原因很简单，理论部分中，我已经说过在入门阶段只需对神经网络有一个整体的认识即可，实战必须与理论相结合，在理论学习中没有完全搞清楚实现细节，在实战部分通过不使用框架实现神经网络就可以弄清楚细节了吗？很难。当然，如果你很牛，在理论部分已经搞清楚细节了，例如前向/反向传播的具体过程，那么可以先使用 Numpy 等库实现一个简单神经网络。对于大多数人而言，在入门阶段，只需要掌握大概即可，以后还有很多时间了解细节呢。为什么只选择一个框架呢？未来的实战肯定不可能只使用一个框架，甚至有可能需要自己实现框架，但是，在入门阶段，一个足够了，框架隐藏了实现细节，让我们能够专注于神经网络的架构（在这里是优点），而且，在学会使用一个框架后，再学习另一个框架会事半功倍。\n选好框架后，快来选择一个经典的模型上车吧。以我所在的计算机视觉领域举例来说，经典的模型包括 LeNet 5、AlexNet、VGG 等，各个框架都自带了这些经典模型（Pytorch 的在 torchvision 中），先根据官方文档提供的 demo 实际训练一下模型，看一下 CNN 在图片分类上的效果（选择图片分类任务是因为目前该领域最成熟），这里提供 Pytorch 的一个demo。稍微了解了训练流程后，接下来便应该读使用的 demo 中创建神经网络的代码了，例如可以看 Pytorch 官方的VGG模型实现代码。应该如何阅读这部分的代码呢？我建议与原论文或原论文的解析文章进行对照，将模型结构图与模型代码联系起来，因为以后很有可能需要根据模型结构图与描述使用框架构建对应的模型，或者根据模型代码深入理解模型结构，强烈建议在入门阶段便开始锻炼这方面的能力，这与刚入门编程时敲很多代码以熟悉语法和编程有点相似，不同的是：在编程领域这是为了熟悉从现实抽象出来的问题与代码之间的联系，而在这里是为了熟悉模型整体架构与构建出的模型代码之间的联系。当然，急着应用深度学习到实际项目的话可以放低一点要求，知道如何修改现有模型代码的输入层与输出层就可以了。假如觉得代码太长，不够直观，那么直接输出模型结构看看（Pytorch）：\nimport torchvision.models as models model = models.vgg16() print(model) Keras 也可以进行这个操作，使用 model.summary()即可。先不理会 demo 的其它部分代码，好好消化构建模型的方法，这是我觉得入门阶段最适合的方案，因为我觉得入门阶段就接触核心向的东西（深度学习比较简单，所以能在起始阶段便接触偏核心的问题，其它领域不一定喔）能避免以后可能遇到的不少弯路，假如重来一遍，我也不知道这样是不是能保证一切顺利。虽然我在上文当中都是以计算机视觉举例，不过相信想学习 NLP 的读者也可以从中举一反三，知道该如何通过实战进行入门。\n下一步？ 我们直击重点的入门教程算是结束了，虽然我在开头说过自己踩了不少坑，但是写完这篇文章后发现好像并没有怎么提到自己踩过的坑，我知道很多人会问接下来该干什么？在这里我真的可以说一说下一步该干什么。还记得上面的实战部分并没有提到关于读取数据等方面的内容吗，在日后的实战当中，读取数据并输入神经网络其实也是一个重要的部分，除非你确定以后只需使用主流的公开数据集，不然这部分知识就是必需的。接下来你可以先尝试在自己已能成功运行的 demo 上更换负责读取数据集的代码（更换后的代码不应该使用框架提供的常见数据集的 API，如读取 Imagenet 的 API），让模型使用另一个数据集进行训练完成相同的任务（如图片分类），这部分工作可能会花上几天时间，但是完成以后你应该就能真正理解如何向神经网络中输入数据了，除此以外，你有可能会顺便了解到一些数据预处理的简单操作，在实战当中，使用的数据集与模型的原作者使用的数据集总是不同，无论如何，一定要参考原作者的数据预处理步骤，不然有可能出现很大的指标差异。\n弄完了上面提到的东西，接下来真的可以说是海阔天空了，接下来的路就是无数个分叉口，入门后的你可以尝试使用神经网络做一个简单的实战项目，例如：用户上传图片，服务器返回分类结果（早已有大厂提供这个 API 了）；也可以找老师开始下一步的科研；当然也可以继续自学，只不过需要自己把握学习方向了。总之，未来就在脚下，祝各位在炼丹的路上一切顺利。\n","date":"2019-10-04T22:44:08Z","image":"https://viflythink.com/Sharing_experience_about_Deep_Learning/show_hu511971c76d96e375eb435b2748cc4c75_1557603_120x120_fill_q75_box_smart1.jpg","permalink":"https://viflythink.com/Sharing_experience_about_Deep_Learning/","title":"致刚入门深度学习的我——作为过来人的一点经验分享"},{"content":"前言 之前我在使用Github Pages和Hexo搭建个人博客(进阶篇)这一篇博文中已经提到了不考虑使用大型公司提供的网站统计分析服务了，只不过网站统计分析服务还是有必要的，至少能看到有多少人浏览过自己的网站。之所以不采用商业公司提供的分析服务是因为这等于助纣为虐，帮助这些公司建立更精准的用户画像，这些公司可以利用遍布于大半个互联网的自家的跟踪代码对读者进行浏览痕迹的跟踪，从而建立精准的用户画像，我无法接受这种侵犯用户隐私的行为，所以只能考虑自己搭建统计分析服务了。在 Google 上搜了一下后决定采用 Matomo（原名为 Piwik）这个开源的网站统计分析服务。本文主要参考了在Debian 9上安装Matomo Analytics这一个教程，只不过很不巧的是目前 Debain 10 已经发布，这篇教程里的 php7.0 已经过时，但是没关系，下文中提供的安装 php 的指令并没有指定版本，所以对于 Debian 9/10 的用户都是可行的。\n需求 1.基本的 Linux 终端操作经验\n2.一个安装了 Debian 9/10 的服务器（VPS），理论上来说 Ubuntu 18 也可以（并没有实测过）\n3.一个属于自己的域名，并且已经将其 DNS 解析指向自己的服务器\n操作 先安装必须的库：\nsudo apt install unzip apt-transport-https curl wget dirmngr php php-fpm php-curl php-gd php-cli php-mysql php-xml php-mbstring  安装 MySQL 的替代品 MariaDB，这里必须提到的一点是，从 Debian9 开始，软件包仓库中的 MySQL 实际上已经全被 MariaDB 取代了：\nsudo apt install mariadb-server  运行 mysql_secure_installation 脚本以改进 MariaDB 安装的安全性：\nsudo mysql_secure_installation  作为数据库 root 用户登录到 MariaDB（注意，必须使用 root 权限才可以作为数据库 root 用户登录到 MariaDB，数据库的 root 用户与系统中的 root 用户不是同一个东西）：\nsudo mysql -u root -p  假如没有一个用于 Matomo 的数据库用户的话，先执行以下指令新建数据库用户，localhost 意味这个用户只可以本地登录（PS：记得将username和password替换为自己准备设置的用户名和密码，下同）：\nCREATE USER 'username'@'localhost' IDENTIFIED BY 'password';  创建后请记住用户名和密码。\n创建一个新的 MariaDB 数据库并授权：\nCREATE DATABASE db_name; GRANT ALL ON db_name.* TO 'username' IDENTIFIED BY 'password'; FLUSH PRIVILEGES; quit;  安装 nginx：\nsudo apt install -y nginx  新建 Nginx 配置文件：\nsudo nano /etc/nginx/sites-available/matomo  在其中填入（将 your_domain 替换为你的域名，例如 stats.viflythink.com，fastcgi_pass 的内容请根据自己的版本进行填写，你可以通过 ls /run/php/ 看到对应的 sock 文件）：\nserver { listen 80; server_name your_domain; root /var/www/html/matomo; location / { try_files $uri /index.php$is_args$args; } location ~ \\.php$ { try_files $uri =404; include fastcgi_params; fastcgi_pass unix:/run/php/php7.0-fpm.sock; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; } }  通过建立软链接将刚写好的配置文件对应的网站设置为可访问的：\nsudo ln -s /etc/nginx/sites-available/matomo /etc/nginx/sites-enabled/  测试配置：\nsudo nginx -t  创建 matomo 目录：\nsudo mkdir -p /var/www/html/matomo  下载和解压 matomo：\ncd /var/www/html/matomo wget https://builds.piwik.org/piwik.zip unzip piwik.zip rm piwik.zip mv piwik/* . rmdir piwik  更改该目录的所有权，确保访问者可以访问这些页面文件：\nsudo chown -R www-data:www-data /var/www/html/matomo  重新加载 Nginx 以让配置生效：\nsudo systemctl reload nginx.service  接下来使用浏览器打开 Nginx 配置文件中填写的域名，按照指引完成 matomo 的安装。\n","date":"2019-08-18T00:00:00Z","image":"https://viflythink.com/Install_Matomo_on_Debian/show_hu237d0d0f8f01f491cebef0f12a3b29f0_514050_120x120_fill_q75_box_smart1.jpg","permalink":"https://viflythink.com/Install_Matomo_on_Debian/","title":"Debian 安装 Matomo (Piwik) 开源统计分析服务"},{"content":"前言 之前在购买 VPS 和域名时发现很多国外商家只支持 VISA，MASTERCARD 这两家的信用卡或者 PayPal，虽然国区 PayPal 可以绑定银联的借记卡/信用卡，但是除了这些以外我还有在 Google Play 购物的需求，未来也会有更多的境外支付的需要，目前我已经忍受不了每次去 Google Play 购物时都要先去淘宝买个礼品卡这个操作了，所以决定采用一个一劳永逸的办法：办理一张外币信用卡（准确来说是走非银联结算通道的信用卡）。我原本以为作为大学生办理一张外币信用卡会比较麻烦，不过想到之前在少数派看过《给普通大学生的境外支付指南》和《学生党 Google Play 剁手经验分享》，所以决定照此进行尝试。PS：本文都是我的个人经验分享，不一定完全有效，同时也可能具有时效性，仅作参考。\n大学生申请外币信用卡的方法 按照我的估计，很多大学生都没有考虑过申请信用卡，日常消费只需要借记卡绑定微信支付和支付宝就没问题了，有关于信用卡与借记卡的区别，是否应该申请信用卡，google 一下就能找到不少靠谱的回答，我就不多说了。不过大约十几年前大学生申请信用卡真的很难，由于申请信用卡时需要经过银行的资产审核，而大学生又没有工作，所以对于很多大学生来说是几乎不可能申请到信用卡。不过近年来已经有相当多的银行推出了大学生专属信用卡，上述的问题已经不复存在。然而别以为随便申请一张大学生信用卡就可以在 Google Play 之类的国外商店上购物了，想要在 Google Play 上购物，你需要一张非银联的信用卡（借记卡也行，但我只记得中国银行的 EMV 卡属于这一类）。注意，必须是非银联的卡，因为很多国外付款方式都不支持银联。除此以外，借记卡/信用卡还有单币/双币/全币的区别，只不过 VISA 和 MASTERCARD 基本上都是使用美元结算的，所以我们几乎不需要关心这个差别。在满足非银联的这个条件下，我们来选择一间银行的信用卡，参考学姿势的《大学生信用卡申请姿势》，里面对比了各个银行的大学生信用卡的区别，我们主要关注的是是否有 VISA 或 MasterCard 等非银联的卡，当然我也建议最好看下学姿势的其它文章，以后想要靠信用卡享受各种福利（俗称薅羊毛）的话可先要熟悉各家银行的信用卡的区别哦。\n以我申请的民生银行 more 世界卡为例，我先参考了《民生银行大学生信用卡申请指引》，然后通过民生银行官网进行申请（请注意是否为大学生版，大学生版是不需要填职业等信息的，如果不确定的话，点击学姿势的民生银行学术卡申请通道），在申请页面上如实填写必填的个人信息，在这当中，亲属手机号应该是最麻烦的，因为银行会根据这个手机号给你的家长发送短信，如果你的家长不同意你办信用卡，那么这里提供两个办法：\n1.假如你有一个手机号是你的家长的手机号的附属号码，那可以直接填这个手机号，然后在本人手机号填入一个使用自己的身份证注册的手机号。\n2.在家长的手机上设置短信骚扰拦截（每个国内 ROM 应该都有这个功能吧），根据短信内容设置关键字，短信的具体内容可看下方，例如可以设置拦截“民生银行”。\n 【民生银行】尊敬的A，您好！您的亲属B已向民生银行提交信用卡申请，我行预审通过，预计为其核发卡片的信用额度为5000.00元，具体申请事宜请您联系申请人核实。如您对本次申请存在异议，请于Y年M月D日24点前短信回复“QXSQ”，我行将终止本次申请。超过上述时间未回复则视为您同意本次申请。感谢您的支持！\n 搞定这些麻烦的申请步骤后，就是等待银行进行资料审核了。不出意外的话，大约一个星期后你就能收到通过信用卡申请的短信，假如不幸被拒的话，请回忆下自己是否填错了一些个人信息，或者之前是否曾有过欠钱没还的不良行为（例如花呗忘了还），或者学校不在某些银行的白名单当中。\n在发送短信告诉申请者通过信用卡申请后，银行会通过邮寄方式将信用卡寄给申请者，稍微等个两天，信用卡就到了！\n不过很可惜的是，刚到手的信用卡还不能被使用，需要进行激活后才可正常使用，有一些银行可以网上激活，然而民生银行是要求持卡人必须到柜台进行当面激活的，假如你在比较偏远的城市，这个就不太好办了。另外，我很想吐槽一下民生银行的初始信用卡密码设置手续，这 TM 居然需要我打电话进行设置，就完全没有考虑过安全性的问题吗？信用卡激活后，申请信用卡的整个过程总算是结束了，恭喜各位打开了新世界的大门。\n外币信用卡到手后 既然有了外币信用卡，那么很多国外商家的大门已经对我们敞开了。Google Play，美区 App Store，美区/日区亚马逊等商店都可以让我们疯狂剁手，还可以订阅 Spotify，Netflix 等流媒体服务。读到这里的读者可能都没有使用信用卡购物的经验，不过没关系，使用外币信用卡购物并不麻烦，一般而言只需填入信用卡卡号，CVC 码（信用卡背面的一个三位数），有效日期就可以了，以 Google Play 为例，说一下如何添加外币信用卡作为付款方式。\n在Google Play上添加外币信用卡作为付款方式 与申请信用卡相比，这节内容可以说是简单多了，直接根据图片操作即可（我已经添加了付款地址，如果之前尚未添加，那么在要求输入付款地址时可以随便输入相关信息，亲测姓名和地址等信息可以与信用卡上的信息不同；另外，确保信用卡里有大于等于 1 美元的余额/额度）：\n1.打开 Google Play，在侧边栏找到“付款方式”并点击\n 付款方式 \n2.点击“添加信用卡或借记卡”，按照要求输入信用卡卡号，CVC 码，有效日期（别填错了！！！）等\n 添加信用卡或借记卡 \n3.假如一切顺利的话，现在即可使用信用卡在 Google Play 上购买东西了，出现问题的话可参考《学生党 Google Play 剁手经验分享》中的“添加卡片并购物”一节进行解决，懒得与客服沟通的话可以先试着申请美区 PayPal 帐号，然后选择美区 PayPal 作为付款方式。\n一些小贴士 1.可以考虑使用外币信用卡申请美区 PayPal 帐号，使用 Paypal 付款更安全。 2.请善用 Google Play 中的心愿单功能，不急着买但想买的东西可放入心愿单中，等待打折，在黑色星期五的时候，很多 App 都会有幅度非常大的折扣。 3.外币信用卡建议设置自动购汇还款，一般在银行 App 中可设置此项，能免去每月手动购汇还款的麻烦，而且不用担心自己忘了还款。\n4.记得还款，各家银行的最后还款期限不尽相同，在每个月的最后还款期限前请确认一下自己是否已还款。\n5.再次强调，请注意用卡安全，信用卡背面的信息不要随便泄漏给别人。\n","date":"2019-07-28T00:00:00Z","image":"https://viflythink.com/How_to_apply_for_non_UnionPay_credit_and_shopping_as_college_student/show_huaff71883e98ee903fc7739a11477cedc_666740_120x120_fill_box_smart1_3.png","permalink":"https://viflythink.com/How_to_apply_for_non_UnionPay_credit_and_shopping_as_college_student/","title":"作为大学生的我如何申请外币信用卡并用于境外支付"},{"content":"2019.8.18.更新：增加了如何搭建自己的统计分析服务的说明。\n2019.9.13.更新：增加了更多的 SEO 内容，对一些内容进行修改。\n2019.11.9.更新：增加了 Material 主题添加随机标语（slogan）的方法。\n在上一篇博文当中我已经说完了使用 GitHub Pages 和 Hexo 搭建博客的基础操作了，只是这个刚搭建好的博客还缺了不少经常能在别人的博客上看到的东西，例如 RSS 订阅，评论区等功能。同时，不知道各位有没有发现一个问题，在搜索引擎当中搜索自己的站点时，搜索引擎返回的结果中并不会出现你的站点。本篇教程将会说明如何解决这些问题，如果还有更多的问题，请在评论区留言。\n额外的功能与服务 下面提到的这些功能与自己使用的 Hexo 主题相关，存在某些主题并没有提供某项功能的可能性\nRSS 订阅 想要提供 RSS 订阅这个功能，各位需要查看自己使用的 Hexo 主题的文档进行操作，以我使用的 Material 主题为例，官方文档简单地说明了一下，其实就是在安装了hexo-generator-feed 插件后，修改 Material 主题下的配置文件（_config.yml）中的 rss:的值：\nurl: rss: atom.xml  按照这样配置的话，你的博客的 RSS 订阅地址就是 https://你的博客域名/atom.xml，例如我的博客的 RSS 订阅地址就是 https://vifly.github.io/atom.xml。\n评论区 依然使用 Material 主题举例子，官方文档也说明了如何设置评论系统，为了能让读者畅所欲言，我否决了全部的国内评论系统，同时为了不翻墙的读者的体验以及匿名评论的需求，我最后选择了 Material 主题提供的 Disqus 加自建 Isso 评论系统（这里要感谢 Alynx Zhou 提供的多评论系统前端代码，话说周老师不去当前端工程师是不是太浪费了鸭≧▽≦）。\n数据统计与分析 继续贴官方文档。基于对读者隐私的考虑，我直接排除了百度和 CNZZ 的分析系统，至于 Google 分析，考虑到谷歌近年来的名声与未翻墙用户的体验，最终也决定不予采用，那么就只剩下一条路了，自己搭建分析系统。这个暂时也咕咕咕了，若是能成功搭建的话，再写一篇博文进行叙述。 目前已经成功使用 Matemo 搭建了自己的网站统计分析服务，具体操作请看Debian 安装 Matomo (Piwik) 开源统计分析服务。\n搜索引擎优化（SEO） 假如你在搜索引擎中输入 site:xxxxx.github.io（自己的博客网址） 后发现没有出现自己的网站，那么请赶快看一下下面的“提交网站站点地图”小节。\n验证网站所有权 为了便于以后在各个搜索引擎当中管理和查看我们的博客，我强烈建议在各个搜索引擎验证网站所有权，完成这一步后即可使用站长工具查看数据了，而且这也是完成后面某些步骤的必要前提。假如你将自己的域名（指的是 *.github.io 以外的域名）用作博客的域名，那么便可以通过添加 DNS 记录的方式验证所有权（PS：每家搜索引擎对这个验证方法有不同的称呼，谷歌称为“域名提供商”，而 Bing 称为“手动向 DNS 添加 CNAME 记录”），不采用下面提到的方法了。\nGoogle 前往 Google 搜索的控制台添加自己的博客地址即可，Google 提供了几种验证方式:\n Google 的网站所有权验证  对于 Material 主题，请使用 HTML 标记或 Google 分析（假如你的博客使用了 Google 分析）进行验证，具体操作只需看官方文档。\nBing（必应） 前往 Bing 的网站管理员工具进行验证。很不幸的是，Material 主题官方并没有提供 Bing 的站点所有权验证，那只能自己动手修改源代码了，经过一番查找，终于找到了用于在 HTML 页面当中标记所有权的部分，其代码位于 themes/material/layout/_partial/head.ejs 中，CTRL+F 查找“site_verification”发现在约 142 行的位置就是我们要找的代码，在下方照葫芦画瓢地加上：\n\u0026lt;% if(theme.head.site_verification.bing) { %\u0026gt;\u0026lt;meta name=\u0026quot;msvalidate.01\u0026quot; content=\u0026quot;\u0026lt;%= theme.head.site_verification.bing %\u0026gt;\u0026quot; /\u0026gt;\u0026lt;% } %\u0026gt;  注意，我感觉这里的 meta name 不一定对于每个人都适用，请观察一下 Bing 提供的 HTML 代码后再修改 head.ejs。\n Bing 的网站所有权验证  在复制了“\u0026lt;meta name=\u0026ldquo;msvalidate.01\u0026rdquo; content=\u0026ldquo;xxxxxxxxxx\u0026rdquo; /\u0026gt;”中的 xxxxxxxxxx 对应的值后，在主题的_config.yml 中进行修改：\nsite_verification: bing: xxxxxxxxxx google: baidu:  提交网站站点地图 这一步就是告诉搜索引擎你的网站有哪些链接，提交后搜索引擎就会自动顺着站点地图中的链接爬取你的站点内容了，若是没有这一步，在搜索引擎当中直接搜索自己的博客地址是没有任何结果的。要完成这一步骤，需要在博客目录下输入以下指令安装hexo-generator-sitemap 插件：\nnpm install hexo-generator-sitemap --save  这个插件默认站点地图生成路径为 https://你的博客域名/sitemap.xml，在使用 hexo g 重新生成网址内容后，将此网址提交到各个搜索引擎就可以了，以 Google 为例子，只需要发送 http://www.google.com/ping?sitemap=https://你的博客域名/sitemap.xml 这个网络请求即可，也可以在Google 搜索控制台中的 sitemaps（站点地图）一栏提交自己的站点地图。而 Bing 则是需要在其 Web 面板中添加 sitemap。\n提交网页地址（收录新页面） 虽然搜索引擎会自动顺着站点地图爬取网页内容，但是我就是想让它赶快收录刚发布的文章（因为不知道这个这个自动流程需要多少时间），这种时候该怎么办呢？我从“SEO 技巧！如何最快时间让 Google 收录你的页面”中了解到了如何让 Google 及时收录新发布的博文，然而 Google 的控制台页面已经进行了改版，经过一番搜索，在Google 官方的帮助文档找到了新的提交新页面的方法，打开https://www.google.com/webmasters/tools，转到网址检查，输入你的新页面的网址，这就可以及时提交新的网页了。\n 网址检查 \nSEO 进阶 为了让搜索引擎更好地爬取我们的网页，还需要使用一些技巧。这一部分主要参考了 Hexo 博客 Next 主题 SEO 优化方法这一博文，虽然 Material 主题与 Next 主题不同，不过有不少地方还是共通的。\n修改文章链接地址 Hexo 默认的文章链接形式为 domain/year/month/day/postname，这种四级 url 形式对于搜索引擎而言并不友好，我们可以修改为 domain/postname 这种形式。打开 blog 根目录下的_config.yml（下面统称为站点配置文件），找到 permalink 部分，将 permalink: :year/:month/:day/:title/改为 permalink: :title.html。\n#permalink: :year/:month/:day/:title/ permalink: :title.html  出站链接添加 nofollow 标签 博文中总是会引用其它的文章，为了不让搜索引擎跳转到其它的网站，专注于我们的网页，我们需要为这些站外链接设置 nofollow 标签，可以通过安装hexo-autonofollow 自动完成这一个步骤。\nnpm install hexo-autonofollow --save  然后在站点配置文件中添加（更多配置请看 GitHub 页面）：\nnofollow: enable: true  添加文章描述 由于在 Material 主题中，文章的 tags 等于 keywords，所以无需再添加关键字了。不过我们可以为每篇博文添加描述，添加方法与添加 tags 等相似，在博客文章 markdown 文件开头添加 description：\n--- title: 标题 date: year-month-day xx:xx:xx tags: [tag01,tag02] description: 你的博文描述 ---  个性化 启用自己的域名 千篇一律的 xxxxxxx.github.io 总是让人觉得厌烦，说到个性化，怎么能缺少使用自己喜欢的域名作为博客网址这一项呢？使用自定义的域名更有可能让人记住你的博客，而且只要不是前往 GoDaddy 这种价格偏高的网站购买域名，一个普通的 com 顶级域名每年也只需花费 10 美刀左右就可以拥有。在这么多的域名服务商当中，我选择了国外的namecheap，主要的好处就是以下几点：\n 价格便宜（从网站名字就可以看出来了） 老牌商家，服务可靠。别看这个网站的页面长得不好看，而且价格也比较便宜，但这个网站真的是老牌服务商，我并没有找到它坑客户的案例，基本可以放心。 提供免费的 WhoisGuard 服务，保护你的隐私。 不用备案，选择国外的域名服务商的话都能享受到这点。  自定义的域名与 GitHub Page 的绑定 买好了域名，接下来要做的事就是让我们的域名能够指向自己的博客啦。这个操作流程十分简单，只需前往自己的域名服务商的控制面板，然后参考这条知乎回答进行操作，只需在域名解析当中添加两条 CNAME 记录让域名（以我的域名为例就是 viflythink.com 和 www.viflythink.com ）指向 xxxxxx.github.io，大概就是下面这样：  设置DNS解析 \n然后在 source 目录下新建一个叫 CNAME 的文本文件，里面填入你的域名（如 viflythink.com），与不少网上的操作不同，我们这里并不需要绑定 GitHub 的 IP，因为有时候 IP 地址会变化，所以绑定 xxxxxx.github.io 会更好。\n启用 HTTPS 加密 为了保证读者的隐私，防止 ISP 的广告植入，稍微提高自己的网站在搜索引擎中的权重，我们需要为自己的域名启用 HTTPS 加密，当你成功启用 HTTPS 加密后读者访问你的网站时就会看到浏览器上出现一个绿色小锁头了，整个步骤也不难，这里参考了为 GitHub Pages 自定义域名并添加SSL-开启https强制这一篇博文，使用 cloudflare 提供的免费服务，这里必须提醒一句，使用 cloudflare 的 Universal SSL 并不意味着全程加密，这个服务其实是通过 cloudflare 自己的服务器进行中转，读者到 cloudflare 的服务器这一段路是加密的，而 cloudflare 到 GitHub 的这一段并没有加密，另外，我在部署后出现“重定向次数过多”的错误，将 cloudflare 的加密由 Flexible 转为默认的 FULL 后就可以了，暂不知道原因。\nMaterial 主题的进阶设置 Material 主题实现随机显示标语（slogan） 是否觉得仅仅一句标语（格言）不足以说明什么呢？我想要在博客首页的标语更能表达我自己，使用随机显示的标语是一个很好的主意，这样就可以使用多个名言警句了，但是 Google 了一番后并没有找到为 Material 主题设置随机标语的方案，那么只能自己动手了（在改源码的道路上越走越远）。这里主要参考了萌狼的新约伊兹的萌狼乡手札诞生全过程伪实录里的“实现动态格言”部分，由于我不懂前端，所以最后只能做到在每次刷新网页后显示随机的标语，而不能动态刷新。这里记录下我的折腾过程，欢迎前端大佬帮忙改进。\n首先找到 Material 主题负责显示标语的代码，其路径是 themes/material/layout/_partial/daily_pic.ejs，可以看到相关代码：\n\u0026lt;div class=\u0026quot;mdl-card__media mdl-color-text--grey-50\u0026quot; style=\u0026quot;background-image:url(\u0026lt;%= url_for(theme.img.daily_pic) %\u0026gt;)\u0026quot;\u0026gt; \u0026lt;p class=\u0026quot;index-top-block-slogan\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;\u0026lt;%= theme.url.daily_pic %\u0026gt;\u0026quot;\u0026gt; \u0026lt;% if(theme.uiux.slogan) { %\u0026gt; \u0026lt;% if(Array.isArray(theme.uiux.slogan)) { %\u0026gt; \u0026lt;%- theme.uiux.slogan.join('\u0026lt;br\u0026gt;') %\u0026gt; \u0026lt;% } else { %\u0026gt; \u0026lt;%- theme.uiux.slogan %\u0026gt; \u0026lt;% } %\u0026gt; \u0026lt;% } %\u0026gt; \u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt;  这部分最后会被转换为 HTML 文本，然而我们需要每次加载时都能显示不同的标语，该怎么办呢？答案是使用 document.addEventListener() 设置一个监听器，加载多个标语后随机选择一个显示，这就是我写的代码的思路，当然，由于我是一个前端小白，所以借鉴了萌狼的代码，期间遇到了“$ is not defined”的错误，按照查到的stackoverflow 上的回答成功解决了（说的简单，其实为了读懂相关的代码花了不少时间），最后写出的能用的代码如下（使用下面的代码替换上面贴出的代码）：\n\u0026lt;div class=\u0026quot;mdl-card__media mdl-color-text--grey-50\u0026quot; style=\u0026quot;background-image:url(\u0026lt;%= url_for(theme.img.daily_pic) %\u0026gt;)\u0026quot;\u0026gt; \u0026lt;p id=\u0026quot;myslogan\u0026quot; class=\u0026quot;index-top-block-slogan\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;\u0026lt;%= theme.url.daily_pic %\u0026gt;\u0026quot;\u0026gt; 无法加载 gists 上的标语 \u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;!-- 动态显示标语 --\u0026gt; \u0026lt;script src=\u0026quot;js/jquery.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; document.addEventListener(\u0026quot;DOMContentLoaded\u0026quot;, function() { jQuery.getJSON( \u0026quot;https://api.github.com/gists/7a04e2188185ddb19cbd19d8217b9400\u0026quot;, function(data) { slogans = JSON.parse(data.files[\u0026quot;slogans.json\u0026quot;].content); randomSlogan = slogans[ Math.floor( Math.random() * slogans.length ) ]; jQuery(\u0026quot;#myslogan\u0026quot;).html(randomSlogan.content); }); }); \u0026lt;/script\u0026gt;  可以看出，使用了 jQuery 来解析 json 文件和提取标语内容，也用来更改页面中的标语，用 myslogan 这个 ID 标记标语所在区域。另外，想要使用这个代码的话，需要在gist 上创建一个 json 文件，其格式类似于这样（与萌狼不同的是，我的代码并没有显示名言作者，所以这里的 json 文件并不需要填写 author）：\n[ { \u0026quot;content\u0026quot;:\u0026quot;example1\u0026quot; }, { \u0026quot;content\u0026quot;:\u0026quot;example2\u0026quot; }, ]  然后将得到的类似于https://gist.github.com/7a04e2188185ddb19cbd19d8217b9400这样的网址里的\u0026quot;gist.github.com\u0026quot;替换为\u0026quot;api.github.com/gists\u0026quot;，再用这个替换后的网址替换上面代码中的 gist 网址。完成后就能实现打开首页时随机显示标语了。\n","date":"2019-07-15T00:00:00Z","permalink":"https://viflythink.com/Use_GithubPages_and_Hexo_to_build_blog_advanced/","title":"使用 GitHub Pages 和 Hexo 搭建个人博客(进阶篇)"},{"content":"简介 Github Pages是什么 先看看维基百科的说法:\n GitHub Pages是GitHub提供的一个网页寄存服务，于2008年推出。可以用于存放静态网页，包括博客、项目文档甚至整本书。\n 阮一峰的这篇文章的说法更为简短：\n github Pages可以被认为是用户编写的、托管在github上的静态网页。\n 根据维基百科的介绍，我们可以得知 Github Pages 可用来存放博客，而且是免费且无限存储容量的，只不过它只支持静态网页，也就是说无法使用 WordPress 等工具建站。\nHexo是什么 先上一个官方的介绍：\n Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。\n 从官方介绍中我们可以得知Hexo 是用来生成静态网页的。 由于 Github Pages 上只能发布静态网页，所以我们需要找到一个生成静态网页的软件来让我们能快速发布博文，Hexo 就是其中的一个。github 官方是推荐使用 Jekyll 来生成和发布的，然而 Hexo 有许多好看的主题，为此我选择了 Hexo。\n本地搭建 安装与运行 Windows 下请自行下载安装 nodejs 与 git，Linux 请根据自己所使用的发行版安装 nodejs，npm，git。\n安装好后输入以下指令安装 hexo-cli（g 参数代表全局，请无视运行过程中出现的错误）：\nnpm install hexo-cli -g  然后在博客目录下输入以下指令：\nnpm install hexo --save  完成后可输入 hexo -v 验证是否安装成功。\n接着输入以下指令进行初始化：\nhexo init  然后输入以下指令安装依赖：\nnpm install  搞定后就可以运行一下测试效果了，生成静态网页：\nhexo g  运行本地服务器：\nhexo s  根据输出信息使用浏览器打开http://localhost:4000，即可看到效果\n写文章 可以使用命令行或手动创建方法新建博文。 使用命令行：\nhexo new \u0026lt;title\u0026gt;  手动创建：在博客根目录下 source -\u0026gt; _posts 新建以 .md 为后缀的文件。\n主题选择 就我个人而言，查看技术类博文时总是看到写博文的博主使用了 Next 主题，虽然很简洁，但我总感觉过度简单了，在 16：9 的屏幕上左右两侧的空白太多了。经过一番查找，我选择了在集成服务和美观程度上成功打动了我的 Material 主题。\n使用Material主题后运行报错 使用 Material 主题后，运行 hexo s 后打开网页报错：\nUnhandled rejection TypeError: /home/blog/themes/Material/layout/layout.ejs:3 1| \u0026lt;!DOCTYPE html\u0026gt; 2| \u0026lt;html style=\u0026quot;display: none;\u0026quot; \u0026lt;% if(config.language !== null) { %\u0026gt;lang=\u0026quot;\u0026lt;%- config.language.substring(0,2) %\u0026gt;\u0026quot;\u0026lt;% } %\u0026gt;\u0026gt; \u0026gt;\u0026gt; 3| \u0026lt;%- partial('_partial/head') %\u0026gt; 4| 5| \u0026lt;% if(page.layout === 'gallery') { %\u0026gt; 在官方仓库的 issues 中找到了解决方法，需要对 layout/_widget/dnsprefetch.ejs 进行修改：\n将\n\u0026lt;% } else if(theme.comment.use.startsWith(\u0026quot;disqus\u0026quot;)) { %\u0026gt;  改为\n\u0026lt;% } else if(theme.comment.use \u0026amp;\u0026amp; theme.comment.use.startsWith(\u0026quot;disqus\u0026quot;)) { %\u0026gt;  配置 站点配置 首先打开 blog 根目录下的_config.yml（下面统称为站点配置文件），按照以下示例进行修改：\ntitle: 你的站点名称 author: 你的名字 language: zh-CN  注意冒号后必须有空格，如果你不喜欢默认主题的话，可自行寻找 Hexo 主题，按照对应的主题的说明文档进行安装，记得修改 theme 内容：\ntheme: 新主题名字  Material主题配置 这里按照Material主题官方文档配置即可，选择 Material 主题的一个重要原因就是这个主题提供了很多对第三方服务的支持（前端小白的福音），所以看看有什么需要的第三方服务吧（RSS，评论区，访问统计等等）,可以参考我写的进阶篇。\nMaterial主题文档的一个小坑 在配置过程中遇到了一个问题，不知道如何在侧边栏添加独立页面的入口（比如关于，友链之类的），添加后点击入口却无法进入对应的页面，官方文档说明如下：\n link 的参数为相对路径，对应 hexo 目录下的 source 文件夹内的相应文件夹。\n 然而我已经按照说明创建了文件夹，为什么还是不行呢？最后在这个页面找到了解决方法，以创建关于页面为例：\n在 source 文件夹下创建 about 文件夹，新建一个 index.md 文件，写下（其中 layout 的值不可修改）：\n--- title: about date: layout: about ---  假如是创建友链页面的话，记得还要按照“添加数据”这个步骤进行操作。 总结一下，其实是官方文档没有提到需要创建 index.md 这一点坑了我，我还一直以为是我对文档的理解有误呢。\n部署到Github Pages Github上的准备 这部分参考知乎专栏上的超详细Hexo+Github博客搭建小白教程，打开github并登录你的帐号，如果你还没在 github 帐号中添加 ssh key，请参考这篇文章进行添加。接着点击右上角的个人头像，再点击 Your repositories：\n 进入项目页面 \n点击右侧的 New 新建项目。当然，你也可以直接点击这个链接新建项目。输入自己的项目名字，后面一定要加.github.io 后缀，README 初始化也要勾上。\n 新建项目 \n创建好项目后，点击 Settings，向下拉到最后有个 GitHub Pages，点击 Choose a theme 选择一个主题。然后等一会儿就可看到页面了。\n正式部署到Github Pages 打开站点配置文件，按以下示例进行修改：\ndeploy: type: git repository: 你的github项目地址 branch: master  repository 填写的应是类似于 git@github.com:vifly/viflyblog.github.io.git 这样的 ssh 地址。假如你不知道地址，那么可以打开你在 github 上的这个项目，点击右侧的 Clone or download，就会出现所需的地址：\n 查看项目ssh地址 \n最后，发布到 Github Pages：\nhexo d  假如一直卡住的话，可中断后加上 -debug 参数再次运行这个部署指令，查看哪里出现问题。\n","date":"2019-04-07T00:00:00Z","permalink":"https://viflythink.com/Use_GithubPages_and_Hexo_to_build_blog/","title":"使用 Github Pages 和 Hexo 搭建个人博客"}]